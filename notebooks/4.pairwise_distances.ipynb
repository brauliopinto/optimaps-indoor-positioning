{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5700c2ea",
   "metadata": {},
   "source": [
    "### Pairwise distances as a measure of RSSI diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ca20e",
   "metadata": {},
   "source": [
    "#### 1. Expected RSSI in each testing point to get the pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a70db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path().resolve().parent  # Go up from notebooks to thesis\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b9672",
   "metadata": {},
   "source": [
    "- Pairwise distances between RSSIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069083f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import distances, LogParams, expected_rssi, df_test, df_AP\n",
    "from typing import List\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pairwise_rssi_distances(distances: List[dict] = distances,\n",
    "                            log_params: LogParams = {'rho_0': 60, 'alpha': 3.5},\n",
    "                            metric: str = 'euclidean') -> List[float]:\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances based on RSSI values using the expected RSSI model.\n",
    "\n",
    "    Args:\n",
    "        rssi_data (pd.DataFrame): DataFrame containing RSSI values with 'x', 'y', and 'rssi' columns.\n",
    "        log_params (LogParams): Parameters for the expected RSSI model.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: List of pairwise distances.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate expected RSSI values based on distances and log parameters\n",
    "    expected_rssi_df = expected_rssi(distances, df_AP, log_params)\n",
    "\n",
    "    # Get all WAP columns from the test dataframe\n",
    "    wap_columns = [col for col in expected_rssi_df.columns if col.startswith('WAP')]\n",
    "    # Extract the RSSI values for the WAPs\n",
    "    rssi_array = expected_rssi_df[wap_columns].values\n",
    "    # Extract unique RSSI arrays from rssi_array\n",
    "    #rssi_array = np.unique(rssi_array, axis=0)\n",
    "\n",
    "    # Calculate pairwise distances\n",
    "    pw_rssi_list = pdist(rssi_array, metric=metric)\n",
    "\n",
    "    return pw_rssi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c824856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], shape=(1007490,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw_rssi_list = pairwise_rssi_distances()\n",
    "pw_rssi_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8defae",
   "metadata": {},
   "source": [
    "- Pairwise distances between coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b42111eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_coord_distances(df_test: pd.DataFrame = df_test,\n",
    "                             metric: str = 'euclidean') -> List[float]:\n",
    "    \"\"\"\n",
    "    Calculate pairwise distances based on coordinates.\n",
    "\n",
    "    Args:\n",
    "        df_test (pd.DataFrame): DataFrame containing coordinates with 'x' and 'y' columns.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: List of pairwise distances.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract coordinates\n",
    "    coords = df_test[['X', 'Y']].values\n",
    "\n",
    "    # Extract unique coordinates\n",
    "    #coords = np.unique(coords, axis=0)\n",
    "\n",
    "    # Calculate pairwise distances\n",
    "    pw_coord_list = pdist(coords, metric=metric)\n",
    "\n",
    "    return pw_coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43021ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], shape=(1007490,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw_coord_list = pairwise_coord_distances()\n",
    "pw_coord_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dfa980",
   "metadata": {},
   "source": [
    "- Select only the RSSIs whose labels pairwise distances are below a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659ac880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 20  # Define a threshold for filtering distances\n",
    "pw_coord_list = pairwise_coord_distances()\n",
    "index_below_threshold = pw_coord_list < threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f601b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples with (rho_0, alpha) values\n",
    "# rho_0 ranges from 40 to 80 with step 2.5\n",
    "# alpha ranges from 1 to 6 with step 0.25\n",
    "param_combinations = []\n",
    "\n",
    "for rho_0 in np.arange(40, 82.5, 2.5):  # 40 to 80 inclusive\n",
    "    for alpha in [round(a, 2) for a in np.arange(1.0, 7.25, 0.25)]:  # 1.0 to 7.0 with 0.1 step\n",
    "        param_combinations.append((rho_0, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a035cb6",
   "metadata": {},
   "source": [
    "- Average pairwise distances with Euclidean metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b05f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pw_distances = []\n",
    "\n",
    "for rho_0, alpha in param_combinations:\n",
    "    log_params = LogParams(rho_0=rho_0, alpha=alpha)\n",
    "    mean_pw_dist = np.mean(pairwise_rssi_distances(distances, log_params, metric='euclidean')[index_below_threshold])\n",
    "    mean_pw_distances.append({\n",
    "        'rho_0': rho_0,\n",
    "        'alpha': alpha,\n",
    "        'mean_pw_distance': mean_pw_dist\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "mean_pw_distances_df = pd.DataFrame(mean_pw_distances)\n",
    "mean_pw_distances_df.sort_values(by=['rho_0', 'mean_pw_distance'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad433818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "output_path = project_root / 'output' / 'mean_pairwise_distances_euclidean.csv'\n",
    "mean_pw_distances_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527722c",
   "metadata": {},
   "source": [
    "- Average pairwise distances with Chebyshev metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19dadd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pw_distances = []\n",
    "\n",
    "for rho_0, alpha in param_combinations:\n",
    "    log_params = LogParams(rho_0=rho_0, alpha=alpha)\n",
    "    mean_pw_dist = np.mean(pairwise_rssi_distances(distances, log_params, metric='chebyshev')[index_below_threshold])\n",
    "    mean_pw_distances.append({\n",
    "        'rho_0': rho_0,\n",
    "        'alpha': alpha,\n",
    "        'mean_pw_distance': mean_pw_dist\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "mean_pw_distances_df = pd.DataFrame(mean_pw_distances)\n",
    "mean_pw_distances_df.sort_values(by=['rho_0', 'mean_pw_distance'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47540e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "output_path = project_root / 'output' / 'mean_pairwise_distances_chebyshev.csv'\n",
    "mean_pw_distances_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd0fa8",
   "metadata": {},
   "source": [
    "- Average pairwise distances with Standardized Euclidean metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09c3f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pw_distances = []\n",
    "\n",
    "for rho_0, alpha in param_combinations:\n",
    "    log_params = LogParams(rho_0=rho_0, alpha=alpha)\n",
    "    mean_pw_dist = np.mean(pairwise_rssi_distances(distances, log_params, metric='seuclidean')[index_below_threshold])\n",
    "    mean_pw_distances.append({\n",
    "        'rho_0': rho_0,\n",
    "        'alpha': alpha,\n",
    "        'mean_pw_distance': mean_pw_dist\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "mean_pw_distances_df = pd.DataFrame(mean_pw_distances)\n",
    "mean_pw_distances_df.sort_values(by=['rho_0', 'mean_pw_distance'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ab80c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "output_path = project_root / 'output' / 'mean_pairwise_distances_seuclidean.csv'\n",
    "mean_pw_distances_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46370d75",
   "metadata": {},
   "source": [
    "- Coefficient of Variation (CV) of pairwise distances with Euclidean metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb071ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pw_distances = []\n",
    "\n",
    "for rho_0, alpha in param_combinations:\n",
    "    log_params = LogParams(rho_0=rho_0, alpha=alpha)\n",
    "    cv_pw_dist = (np.std(pairwise_rssi_distances(distances, log_params, metric='euclidean')[index_below_threshold])/np.mean(pairwise_rssi_distances(distances, log_params, metric='euclidean')[index_below_threshold]))*100\n",
    "    cv_pw_distances.append({\n",
    "        'rho_0': rho_0,\n",
    "        'alpha': alpha,\n",
    "        'cv_pw_distance': cv_pw_dist\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "cv_pw_distances_df = pd.DataFrame(cv_pw_distances)\n",
    "cv_pw_distances_df.sort_values(by=['rho_0', 'cv_pw_distance'], ascending=[True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1f3ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "output_path = project_root / 'output' / 'cv_pairwise_distances_euclidean.csv'\n",
    "cv_pw_distances_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010add9",
   "metadata": {},
   "source": [
    "- Coefficient of Variation (CV) of pairwise distances with Chebyshev metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8357b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pw_distances = []\n",
    "\n",
    "for rho_0, alpha in param_combinations:\n",
    "    log_params = LogParams(rho_0=rho_0, alpha=alpha)\n",
    "    cv_pw_dist = (np.std(pairwise_rssi_distances(distances, log_params, metric='chebyshev')[index_below_threshold])/np.mean(pairwise_rssi_distances(distances, log_params, metric='chebyshev')[index_below_threshold]))*100\n",
    "    cv_pw_distances.append({\n",
    "        'rho_0': rho_0,\n",
    "        'alpha': alpha,\n",
    "        'cv_pw_distance': cv_pw_dist\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better visualization\n",
    "cv_pw_distances_df = pd.DataFrame(cv_pw_distances)\n",
    "cv_pw_distances_df.sort_values(by=['rho_0', 'cv_pw_distance'], ascending=[True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dffcd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "output_path = project_root / 'output' / 'cv_pairwise_distances_chebyshev.csv'\n",
    "cv_pw_distances_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f3db6",
   "metadata": {},
   "source": [
    "### 2. Sorting the combinations acoording to the average error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260242d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NN results shape: (425, 3)\n",
      "Loaded SLSQP results shape: (425, 3)\n",
      "\n",
      "NN results columns: ['rho_0', 'alpha', 'mean_error']\n",
      "SLSQP results columns: ['rho_0', 'alpha', 'mean_error']\n",
      "\n",
      "=== TOP 3 ALPHAS PER RHO_0 ANALYSIS ===\n",
      "Total combinations analyzed: 102\n",
      "Unique rho_0 values: 17\n",
      "Algorithms: ['NN', 'SLSQP']\n",
      "\n",
      "Sample results (first 10 rows):\n",
      "algorithm  rho_0  alpha  mean_error\n",
      "       NN   40.0   6.25        3.09\n",
      "       NN   40.0   6.00        3.12\n",
      "       NN   40.0   5.75        3.19\n",
      "       NN   42.5   5.75        3.03\n",
      "       NN   42.5   6.00        3.09\n",
      "       NN   42.5   5.50        3.14\n",
      "       NN   45.0   5.50        3.02\n",
      "       NN   45.0   5.25        3.05\n",
      "       NN   45.0   5.75        3.08\n",
      "       NN   47.5   5.00        2.99\n",
      "\n",
      "Results saved to: /home/braulio/thesis/output/top3_alphas_per_rho0.csv\n",
      "\n",
      "=== SUMMARY BY ALGORITHM ===\n",
      "\n",
      "NN Algorithm:\n",
      "  Best overall performance: 2.730m\n",
      "  Worst in top-3: 3.190m\n",
      "  Average of top-3 performances: 2.954m\n",
      "  Most frequent alpha values in top-3:\n",
      "    α = 5.75: appears 3 times\n",
      "    α = 4.0: appears 3 times\n",
      "    α = 4.25: appears 3 times\n",
      "    α = 4.5: appears 3 times\n",
      "    α = 4.75: appears 3 times\n",
      "\n",
      "SLSQP Algorithm:\n",
      "  Best overall performance: 2.650m\n",
      "  Worst in top-3: 3.030m\n",
      "  Average of top-3 performances: 2.741m\n",
      "  Most frequent alpha values in top-3:\n",
      "    α = 5.75: appears 3 times\n",
      "    α = 4.0: appears 3 times\n",
      "    α = 4.25: appears 3 times\n",
      "    α = 4.5: appears 3 times\n",
      "    α = 4.75: appears 3 times\n",
      "\n",
      "=== CROSS-ALGORITHM COMPARISON ===\n",
      "NN best performance: 2.730m\n",
      "SLSQP best performance: 2.650m\n",
      "Improvement: 0.080m (2.9%)\n"
     ]
    }
   ],
   "source": [
    "# Load the positioning results data\n",
    "nn_results_file = project_root / 'output' / 'nn_results_by_params.csv'\n",
    "slsqp_results_file = project_root / 'output' / 'optimized_results_by_params.csv'\n",
    "\n",
    "# Load the data\n",
    "nn_results = pd.read_csv(nn_results_file)\n",
    "slsqp_results = pd.read_csv(slsqp_results_file)\n",
    "\n",
    "print(\"Loaded NN results shape:\", nn_results.shape)\n",
    "print(\"Loaded SLSQP results shape:\", slsqp_results.shape)\n",
    "print(\"\\nNN results columns:\", nn_results.columns.tolist())\n",
    "print(\"SLSQP results columns:\", slsqp_results.columns.tolist())\n",
    "\n",
    "# Function to get top 3 alphas for each rho_0\n",
    "def get_top3_alphas_per_rho0(df, algorithm_name):\n",
    "    \"\"\"\n",
    "    For each rho_0 value, find the 3 alpha values that lead to minimum mean_error\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with columns rho_0, alpha, mean_error\n",
    "        algorithm_name: String identifier for the algorithm\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with top 3 alphas per rho_0, sorted in ascending order\n",
    "    \"\"\"\n",
    "    top3_results = []\n",
    "\n",
    "    # Get unique rho_0 values and sort them\n",
    "    unique_rho0 = sorted(df['rho_0'].unique())\n",
    "\n",
    "    for rho_0 in unique_rho0:\n",
    "        # Filter data for current rho_0\n",
    "        rho_data = df[df['rho_0'] == rho_0].copy()\n",
    "\n",
    "        # Sort by mean_error (ascending) and get top 3\n",
    "        top3_for_rho = rho_data.nsmallest(3, 'mean_error')\n",
    "\n",
    "        # Sort the top 3 by alpha in ascending order\n",
    "        top3_for_rho = top3_for_rho.sort_values('alpha')\n",
    "\n",
    "        # Add rank information\n",
    "        for rank, (_, row) in enumerate(top3_for_rho.iterrows(), 1):\n",
    "            top3_results.append({\n",
    "                'algorithm': algorithm_name,\n",
    "                'rho_0': rho_0,\n",
    "                'alpha': row['alpha'],\n",
    "                'mean_error': row['mean_error']\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(top3_results)\n",
    "\n",
    "# Get top 3 alphas for NN algorithm\n",
    "top3_nn = get_top3_alphas_per_rho0(nn_results, 'NN')\n",
    "\n",
    "# Get top 3 alphas for SLSQP algorithm\n",
    "top3_slsqp = get_top3_alphas_per_rho0(slsqp_results, 'SLSQP')\n",
    "\n",
    "# Combine results\n",
    "top3_combined = pd.concat([top3_nn, top3_slsqp], ignore_index=True)\n",
    "\n",
    "# Sort by algorithm, rho_0, and rank\n",
    "top3_combined = top3_combined.sort_values(['algorithm', 'rho_0', 'mean_error'])\n",
    "\n",
    "print(\"\\n=== TOP 3 ALPHAS PER RHO_0 ANALYSIS ===\")\n",
    "print(f\"Total combinations analyzed: {len(top3_combined)}\")\n",
    "print(f\"Unique rho_0 values: {len(top3_combined['rho_0'].unique())}\")\n",
    "print(f\"Algorithms: {top3_combined['algorithm'].unique().tolist()}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nSample results (first 10 rows):\")\n",
    "print(top3_combined.head(10).to_string(index=False))\n",
    "\n",
    "# Save results to CSV file\n",
    "output_file = project_root / 'output' / 'top3_alphas_per_rho0.csv'\n",
    "top3_combined.to_csv(output_file, index=False)\n",
    "print(f\"\\nResults saved to: {output_file}\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== SUMMARY BY ALGORITHM ===\")\n",
    "for algorithm in ['NN', 'SLSQP']:\n",
    "    algo_data = top3_combined[top3_combined['algorithm'] == algorithm]\n",
    "    print(f\"\\n{algorithm} Algorithm:\")\n",
    "    print(f\"  Best overall performance: {algo_data['mean_error'].min():.3f}m\")\n",
    "    print(f\"  Worst in top-3: {algo_data['mean_error'].max():.3f}m\")\n",
    "    print(f\"  Average of top-3 performances: {algo_data['mean_error'].mean():.3f}m\")\n",
    "\n",
    "    # Most frequently appearing alphas in top 3\n",
    "    alpha_counts = algo_data['alpha'].value_counts().head(5)\n",
    "    print(\"  Most frequent alpha values in top-3:\")\n",
    "    for alpha, count in alpha_counts.items():\n",
    "        print(f\"    α = {alpha}: appears {count} times\")\n",
    "\n",
    "# Cross-algorithm comparison\n",
    "print(\"\\n=== CROSS-ALGORITHM COMPARISON ===\")\n",
    "nn_best = top3_combined[top3_combined['algorithm'] == 'NN']['mean_error'].min()\n",
    "slsqp_best = top3_combined[top3_combined['algorithm'] == 'SLSQP']['mean_error'].min()\n",
    "improvement = nn_best - slsqp_best\n",
    "improvement_pct = (improvement / nn_best) * 100\n",
    "\n",
    "print(f\"NN best performance: {nn_best:.3f}m\")\n",
    "print(f\"SLSQP best performance: {slsqp_best:.3f}m\")\n",
    "print(f\"Improvement: {improvement:.3f}m ({improvement_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce70c2",
   "metadata": {},
   "source": [
    "### 3. Best parameter combinations (NN, SLSQP(+), Mean-Euclidean, Mean_Chebyshev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85469ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully:\n",
      "NN results: (425, 3)\n",
      "SLSQP results: (425, 3)\n",
      "Euclidean distances: (425, 3)\n",
      "Chebyshev distances: (425, 3)\n",
      "\n",
      "=== FINDING OPTIMAL PARAMETERS ===\n",
      "NN optimal parameters found: 17 combinations\n",
      "SLSQP(+) optimal parameters found: 17 combinations\n",
      "Mean-Euclidean optimal parameters found: 17 combinations\n",
      "Mean-Chebyshev optimal parameters found: 17 combinations\n",
      "\n",
      "=== COMBINED RESULTS ===\n",
      "Total optimal combinations: 68\n",
      "Algorithms: ['Mean-Chebyshev', 'Mean-Euclidean', 'NN', 'SLSQP(+)']\n",
      "rho_0 range: 40.0 - 80.0\n",
      "\n",
      "Sample results (first 20 rows):\n",
      "     algorithm  rho_0  alpha  mean_error\n",
      "Mean-Chebyshev   40.0   5.50        2.85\n",
      "Mean-Chebyshev   42.5   5.25        2.84\n",
      "Mean-Chebyshev   45.0   5.25        2.71\n",
      "Mean-Chebyshev   47.5   5.00        2.71\n",
      "Mean-Chebyshev   50.0   4.75        2.69\n",
      "Mean-Chebyshev   52.5   4.50        2.67\n",
      "Mean-Chebyshev   55.0   4.25        2.65\n",
      "Mean-Chebyshev   57.5   4.00        2.65\n",
      "Mean-Chebyshev   60.0   3.75        2.66\n",
      "Mean-Chebyshev   62.5   3.50        2.68\n",
      "Mean-Chebyshev   65.0   3.25        2.67\n",
      "Mean-Chebyshev   67.5   3.00        2.68\n",
      "Mean-Chebyshev   70.0   2.75        2.70\n",
      "Mean-Chebyshev   72.5   2.50        2.72\n",
      "Mean-Chebyshev   75.0   2.25        2.75\n",
      "Mean-Chebyshev   77.5   2.00        2.79\n",
      "Mean-Chebyshev   80.0   1.75        2.83\n",
      "Mean-Euclidean   40.0   5.00        3.42\n",
      "Mean-Euclidean   42.5   4.75        3.38\n",
      "Mean-Euclidean   45.0   4.50        3.33\n",
      "\n",
      "Results saved to: /home/braulio/thesis/output/optimal_parameters_by_algorithm.csv\n",
      "\n",
      "=== SUMMARY BY ALGORITHM ===\n",
      "\n",
      "Mean-Chebyshev:\n",
      "  Number of rho_0 values: 17\n",
      "  Alpha range: 1.75 - 5.50\n",
      "  Mean_error range: 2.650 - 2.850\n",
      "  Most frequent alpha: 5.25\n",
      "  Best performance: 2.850 at (ρ₀=40.0, α=5.5)\n",
      "\n",
      "Mean-Euclidean:\n",
      "  Number of rho_0 values: 17\n",
      "  Alpha range: 1.75 - 5.00\n",
      "  Mean_error range: 2.670 - 3.420\n",
      "  Most frequent alpha: 1.75\n",
      "  Best performance: 3.420 at (ρ₀=40.0, α=5.0)\n",
      "\n",
      "NN:\n",
      "  Number of rho_0 values: 17\n",
      "  Alpha range: 1.50 - 6.25\n",
      "  Mean_error range: 2.730 - 3.090\n",
      "  Most frequent alpha: 5.00\n",
      "  Best performance: 2.730 at (ρ₀=67.5, α=2.75)\n",
      "\n",
      "SLSQP(+):\n",
      "  Number of rho_0 values: 17\n",
      "  Alpha range: 1.50 - 6.00\n",
      "  Mean_error range: 2.650 - 2.750\n",
      "  Most frequent alpha: 3.25\n",
      "  Best performance: 2.650 at (ρ₀=55.0, α=4.25)\n",
      "\n",
      "=== PIVOT TABLE: OPTIMAL ALPHA VALUES BY ALGORITHM AND RHO_0 ===\n",
      "algorithm  Mean-Chebyshev  Mean-Euclidean    NN  SLSQP(+)\n",
      "rho_0                                                    \n",
      "40.0                 5.50            5.00  6.25      6.00\n",
      "42.5                 5.25            4.75  5.75      5.75\n",
      "45.0                 5.25            4.50  5.50      5.25\n",
      "47.5                 5.00            4.25  5.00      5.25\n",
      "50.0                 4.75            4.00  5.00      4.75\n",
      "52.5                 4.50            4.00  4.50      4.50\n",
      "55.0                 4.25            3.75  4.25      4.25\n",
      "57.5                 4.00            3.50  3.75      4.00\n",
      "60.0                 3.75            3.25  3.50      3.75\n",
      "62.5                 3.50            3.00  3.25      3.25\n",
      "65.0                 3.25            2.75  3.00      3.25\n",
      "67.5                 3.00            2.75  2.75      2.75\n",
      "70.0                 2.75            2.50  2.50      2.50\n",
      "72.5                 2.50            2.25  2.25      2.25\n",
      "75.0                 2.25            2.00  2.00      2.00\n",
      "77.5                 2.00            1.75  1.75      1.75\n",
      "80.0                 1.75            1.75  1.50      1.50\n",
      "\n",
      "=== PIVOT TABLE: OPTIMAL MEAN_ERROR VALUES BY ALGORITHM AND RHO_0 ===\n",
      "algorithm  Mean-Chebyshev  Mean-Euclidean    NN  SLSQP(+)\n",
      "rho_0                                                    \n",
      "40.0                 2.85            3.42  3.09      2.75\n",
      "42.5                 2.84            3.38  3.03      2.70\n",
      "45.0                 2.71            3.33  3.02      2.71\n",
      "47.5                 2.71            3.32  2.99      2.69\n",
      "50.0                 2.69            3.30  2.94      2.69\n",
      "52.5                 2.67            2.92  2.92      2.67\n",
      "55.0                 2.65            2.90  2.90      2.65\n",
      "57.5                 2.65            2.89  2.86      2.65\n",
      "60.0                 2.66            2.90  2.81      2.66\n",
      "62.5                 2.68            2.86  2.77      2.66\n",
      "65.0                 2.67            2.87  2.77      2.67\n",
      "67.5                 2.68            2.67  2.73      2.67\n",
      "70.0                 2.70            2.68  2.75      2.68\n",
      "72.5                 2.72            2.68  2.77      2.68\n",
      "75.0                 2.75            2.72  2.82      2.72\n",
      "77.5                 2.79            2.73  2.86      2.73\n",
      "80.0                 2.83            2.83  2.94      2.75\n",
      "\n",
      "Analysis complete! Results saved to: /home/braulio/thesis/output/optimal_parameters_by_algorithm.csv\n"
     ]
    }
   ],
   "source": [
    "# Load all the required data files\n",
    "nn_results_file = project_root / 'output' / 'nn_results_by_params.csv'\n",
    "slsqp_results_file = project_root / 'output' / 'optimized_results_by_params.csv'\n",
    "euclidean_file = project_root / 'output' / 'mean_pairwise_distances_euclidean.csv'\n",
    "chebyshev_file = project_root / 'output' / 'mean_pairwise_distances_chebyshev.csv'\n",
    "\n",
    "# Load the data\n",
    "nn_results = pd.read_csv(nn_results_file)\n",
    "slsqp_results = pd.read_csv(slsqp_results_file)\n",
    "euclidean_data = pd.read_csv(euclidean_file)\n",
    "chebyshev_data = pd.read_csv(chebyshev_file)\n",
    "\n",
    "print(\"Data loaded successfully:\")\n",
    "print(f\"NN results: {nn_results.shape}\")\n",
    "print(f\"SLSQP results: {slsqp_results.shape}\")\n",
    "print(f\"Euclidean distances: {euclidean_data.shape}\")\n",
    "print(f\"Chebyshev distances: {chebyshev_data.shape}\")\n",
    "\n",
    "def get_optimal_params_for_algorithm(df, metric_column, algorithm_name, minimize=True, slsqp_data=None):\n",
    "    \"\"\"\n",
    "    Get optimal alpha for each rho_0 based on the specified metric\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with rho_0, alpha, and metric columns\n",
    "        metric_column: Column name to optimize\n",
    "        algorithm_name: Name of the algorithm\n",
    "        minimize: If True, find minimum; if False, find maximum\n",
    "        slsqp_data: DataFrame with SLSQP results for cross-referencing mean_error\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with optimal parameters\n",
    "    \"\"\"\n",
    "    optimal_results = []\n",
    "\n",
    "    # Get unique rho_0 values and sort them\n",
    "    unique_rho0 = sorted(df['rho_0'].unique())\n",
    "\n",
    "    for rho_0 in unique_rho0:\n",
    "        # Filter data for current rho_0\n",
    "        rho_data = df[df['rho_0'] == rho_0].copy()\n",
    "\n",
    "        # Find optimal value (minimum or maximum)\n",
    "        if minimize:\n",
    "            optimal_row = rho_data.loc[rho_data[metric_column].idxmin()]\n",
    "        else:\n",
    "            optimal_row = rho_data.loc[rho_data[metric_column].idxmax()]\n",
    "\n",
    "        # For Mean-Euclidean and Mean-Chebyshev, get mean_error from SLSQP data\n",
    "        if algorithm_name in ['Mean-Euclidean', 'Mean-Chebyshev'] and slsqp_data is not None:\n",
    "            # Find corresponding SLSQP result for this rho_0 and alpha combination\n",
    "            slsqp_match = slsqp_data[\n",
    "                (slsqp_data['rho_0'] == rho_0) &\n",
    "                (slsqp_data['alpha'] == optimal_row['alpha'])\n",
    "            ]\n",
    "\n",
    "            if not slsqp_match.empty:\n",
    "                mean_error_value = slsqp_match['mean_error'].iloc[0]\n",
    "            else:\n",
    "                # If exact match not found, use closest alpha value\n",
    "                slsqp_rho_data = slsqp_data[slsqp_data['rho_0'] == rho_0]\n",
    "                closest_alpha_idx = (slsqp_rho_data['alpha'] - optimal_row['alpha']).abs().idxmin()\n",
    "                mean_error_value = slsqp_data.loc[closest_alpha_idx, 'mean_error']\n",
    "        else:\n",
    "            # For NN and SLSQP(+), use the original metric value\n",
    "            mean_error_value = optimal_row[metric_column]\n",
    "\n",
    "        optimal_results.append({\n",
    "            'algorithm': algorithm_name,\n",
    "            'rho_0': rho_0,\n",
    "            'alpha': optimal_row['alpha'],\n",
    "            'mean_error': mean_error_value\n",
    "        })\n",
    "\n",
    "    return optimal_results\n",
    "\n",
    "# Get optimal parameters for each algorithm\n",
    "print(\"\\n=== FINDING OPTIMAL PARAMETERS ===\")\n",
    "\n",
    "# 1. NN Algorithm - minimize mean_error\n",
    "nn_optimal = get_optimal_params_for_algorithm(\n",
    "    nn_results, 'mean_error', 'NN', minimize=True\n",
    ")\n",
    "print(f\"NN optimal parameters found: {len(nn_optimal)} combinations\")\n",
    "\n",
    "# 2. SLSQP(+) Algorithm - minimize mean_error\n",
    "slsqp_optimal = get_optimal_params_for_algorithm(\n",
    "    slsqp_results, 'mean_error', 'SLSQP(+)', minimize=True\n",
    ")\n",
    "print(f\"SLSQP(+) optimal parameters found: {len(slsqp_optimal)} combinations\")\n",
    "\n",
    "# 3. Mean-Euclidean - maximize mean_pw_distance, get mean_error from SLSQP\n",
    "euclidean_optimal = get_optimal_params_for_algorithm(\n",
    "    euclidean_data, 'mean_pw_distance', 'Mean-Euclidean', minimize=False, slsqp_data=slsqp_results\n",
    ")\n",
    "print(f\"Mean-Euclidean optimal parameters found: {len(euclidean_optimal)} combinations\")\n",
    "\n",
    "# 4. Mean-Chebyshev - maximize mean_pw_distance, get mean_error from SLSQP\n",
    "chebyshev_optimal = get_optimal_params_for_algorithm(\n",
    "    chebyshev_data, 'mean_pw_distance', 'Mean-Chebyshev', minimize=False, slsqp_data=slsqp_results\n",
    ")\n",
    "print(f\"Mean-Chebyshev optimal parameters found: {len(chebyshev_optimal)} combinations\")\n",
    "\n",
    "# Combine all results\n",
    "all_optimal_results = nn_optimal + slsqp_optimal + euclidean_optimal + chebyshev_optimal\n",
    "\n",
    "# Create DataFrame\n",
    "optimal_params_df = pd.DataFrame(all_optimal_results)\n",
    "\n",
    "# Sort by algorithm and rho_0\n",
    "optimal_params_df = optimal_params_df.sort_values(['algorithm', 'rho_0'])\n",
    "\n",
    "print(\"\\n=== COMBINED RESULTS ===\")\n",
    "print(f\"Total optimal combinations: {len(optimal_params_df)}\")\n",
    "print(f\"Algorithms: {optimal_params_df['algorithm'].unique().tolist()}\")\n",
    "print(f\"rho_0 range: {optimal_params_df['rho_0'].min()} - {optimal_params_df['rho_0'].max()}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nSample results (first 20 rows):\")\n",
    "print(optimal_params_df.head(20).to_string(index=False))\n",
    "\n",
    "# Save to CSV file\n",
    "output_file = project_root / 'output' / 'optimal_parameters_by_algorithm.csv'\n",
    "optimal_params_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nResults saved to: {output_file}\")\n",
    "\n",
    "# Display summary statistics by algorithm\n",
    "print(\"\\n=== SUMMARY BY ALGORITHM ===\")\n",
    "for algorithm in optimal_params_df['algorithm'].unique():\n",
    "    algo_data = optimal_params_df[optimal_params_df['algorithm'] == algorithm]\n",
    "    print(f\"\\n{algorithm}:\")\n",
    "    print(f\"  Number of rho_0 values: {len(algo_data)}\")\n",
    "    print(f\"  Alpha range: {algo_data['alpha'].min():.2f} - {algo_data['alpha'].max():.2f}\")\n",
    "    print(f\"  Mean_error range: {algo_data['mean_error'].min():.3f} - {algo_data['mean_error'].max():.3f}\")\n",
    "    print(f\"  Most frequent alpha: {algo_data['alpha'].mode().iloc[0]:.2f}\")\n",
    "\n",
    "    # Show best performance for each algorithm\n",
    "    if algorithm in ['NN', 'SLSQP(+)']:\n",
    "        best_idx = algo_data['mean_error'].idxmin()\n",
    "        print(f\"  Best performance: {algo_data.loc[best_idx, 'mean_error']:.3f} at (ρ₀={algo_data.loc[best_idx, 'rho_0']}, α={algo_data.loc[best_idx, 'alpha']})\")\n",
    "    else:\n",
    "        best_idx = algo_data['mean_error'].idxmax()\n",
    "        print(f\"  Best performance: {algo_data.loc[best_idx, 'mean_error']:.3f} at (ρ₀={algo_data.loc[best_idx, 'rho_0']}, α={algo_data.loc[best_idx, 'alpha']})\")\n",
    "\n",
    "# Create a pivot table for easy comparison\n",
    "print(\"\\n=== PIVOT TABLE: OPTIMAL ALPHA VALUES BY ALGORITHM AND RHO_0 ===\")\n",
    "pivot_alpha = optimal_params_df.pivot(index='rho_0', columns='algorithm', values='alpha')\n",
    "print(pivot_alpha.round(2))\n",
    "\n",
    "print(\"\\n=== PIVOT TABLE: OPTIMAL MEAN_ERROR VALUES BY ALGORITHM AND RHO_0 ===\")\n",
    "pivot_error = optimal_params_df.pivot(index='rho_0', columns='algorithm', values='mean_error')\n",
    "print(pivot_error.round(3))\n",
    "\n",
    "print(f\"\\nAnalysis complete! Results saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
