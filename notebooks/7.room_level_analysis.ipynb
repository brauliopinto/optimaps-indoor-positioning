{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1647d962",
   "metadata": {},
   "source": [
    "#### Additional Analysis Regarding each Room of the Experimental Testbed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5a762",
   "metadata": {},
   "source": [
    "##### 1. Error analysis by room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5cfd17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1420, 19)\n",
      "\n",
      "First few rows:\n",
      "   LABEL DEVICE  WAP96  WAP100  WAP101  WAP102  WAP104  WAP105  WAP106  \\\n",
      "0   1611   1002 -74.00   100.0   100.0  -89.00   100.0   100.0   100.0   \n",
      "1   1611   104D -68.00   100.0   100.0  -81.00   100.0   100.0   100.0   \n",
      "2   1611   10CE -75.20   100.0   100.0  -86.40   100.0   -96.0   100.0   \n",
      "3   1611   1210 -72.50   100.0   100.0  -83.50   100.0   100.0   100.0   \n",
      "4   1611   1211 -68.71   100.0   100.0  -80.86   100.0   100.0   100.0   \n",
      "\n",
      "   WAP107  WAP108  WAP112  WAP114  WAP115  WAP116  WAP117  WAP118    X     Y  \n",
      "0   100.0   100.0   100.0   100.0   100.0   100.0   100.0  -97.00  1.5  10.2  \n",
      "1   100.0   100.0   100.0   100.0   -95.0   100.0   100.0  -98.00  1.5  10.2  \n",
      "2   100.0   100.0   100.0   100.0   100.0   100.0   100.0  -93.25  1.5  10.2  \n",
      "3   100.0   100.0   100.0   100.0   -98.0   100.0   100.0  -95.67  1.5  10.2  \n",
      "4   100.0   100.0   100.0   100.0   -96.2   100.0   100.0  -95.25  1.5  10.2  \n",
      "\n",
      "Unique devices:\n",
      "Number of unique devices: 10\n",
      "Devices: ['1002', '104D', '10CE', '1210', '1211', '1212', '121D', '1F61', '2005', '2055']\n",
      "\n",
      "Unique labels:\n",
      "Number of unique labels: 148\n",
      "Labels: [np.int64(1611), np.int64(1613), np.int64(1615), np.int64(1631), np.int64(1633), np.int64(1635), np.int64(1651), np.int64(1653), np.int64(1655), np.int64(1671), np.int64(1673), np.int64(1675), np.int64(1691), np.int64(1693), np.int64(1695), np.int64(3911), np.int64(3913), np.int64(3915), np.int64(3931), np.int64(3933), np.int64(3935), np.int64(3951), np.int64(3953), np.int64(3955), np.int64(4011), np.int64(4013), np.int64(4015), np.int64(4031), np.int64(4033), np.int64(4035), np.int64(4051), np.int64(4053), np.int64(4055), np.int64(4111), np.int64(4113), np.int64(4115), np.int64(4117), np.int64(4131), np.int64(4133), np.int64(4135), np.int64(4137), np.int64(4151), np.int64(4153), np.int64(4155), np.int64(4157), np.int64(4311), np.int64(4313), np.int64(4315), np.int64(4331), np.int64(4333), np.int64(4335), np.int64(4351), np.int64(4353), np.int64(4355), np.int64(4371), np.int64(4373), np.int64(4375), np.int64(4511), np.int64(4513), np.int64(4515), np.int64(4531), np.int64(4533), np.int64(4535), np.int64(4551), np.int64(4553), np.int64(4555), np.int64(4571), np.int64(4573), np.int64(4575), np.int64(4611), np.int64(4613), np.int64(4615), np.int64(4631), np.int64(4633), np.int64(4635), np.int64(4651), np.int64(4653), np.int64(4655), np.int64(4671), np.int64(4673), np.int64(4675), np.int64(4711), np.int64(4713), np.int64(4715), np.int64(4731), np.int64(4733), np.int64(4735), np.int64(4751), np.int64(4753), np.int64(4755), np.int64(4771), np.int64(4773), np.int64(4775), np.int64(5111), np.int64(5113), np.int64(5115), np.int64(5117), np.int64(5131), np.int64(5133), np.int64(5135), np.int64(5137), np.int64(5151), np.int64(5153), np.int64(5155), np.int64(5157), np.int64(5311), np.int64(5313), np.int64(5315), np.int64(5331), np.int64(5333), np.int64(5335), np.int64(5351), np.int64(5353), np.int64(5355), np.int64(5371), np.int64(5373), np.int64(5375), np.int64(5711), np.int64(5712), np.int64(5714), np.int64(5716), np.int64(5721), np.int64(5722), np.int64(5724), np.int64(5726), np.int64(6121), np.int64(6141), np.int64(6161), np.int64(6181), np.int64(6211), np.int64(6231), np.int64(6251), np.int64(6271), np.int64(6291), np.int64(6341), np.int64(6343), np.int64(6345), np.int64(6347), np.int64(6351), np.int64(6353), np.int64(6355), np.int64(6357), np.int64(61101), np.int64(61121), np.int64(61141), np.int64(62111), np.int64(62131), np.int64(62151)]\n",
      "\n",
      "Data distribution by device:\n",
      "DEVICE\n",
      "1002    141\n",
      "104D    136\n",
      "10CE    146\n",
      "1210    143\n",
      "1211    136\n",
      "1212    141\n",
      "121D    147\n",
      "1F61    144\n",
      "2005    145\n",
      "2055    141\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the test dataset\n",
    "test_data = pd.read_csv('../data/test_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", test_data.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(test_data.head())\n",
    "\n",
    "print(\"\\nUnique devices:\")\n",
    "unique_devices = test_data['DEVICE'].unique()\n",
    "print(f\"Number of unique devices: {len(unique_devices)}\")\n",
    "print(\"Devices:\", sorted(unique_devices))\n",
    "\n",
    "print(\"\\nUnique labels:\")\n",
    "unique_labels = test_data['LABEL'].unique()\n",
    "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
    "print(\"Labels:\", sorted(unique_labels))\n",
    "\n",
    "print(\"\\nData distribution by device:\")\n",
    "device_counts = test_data['DEVICE'].value_counts().sort_index()\n",
    "print(device_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff28dd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL_VECTOR DataFrame:\n",
      "Shape: (10, 2)\n",
      "\n",
      "First few rows:\n",
      "Device: 1002\n",
      "Label Vector: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]...\n",
      "Vector length: 141\n",
      "--------------------------------------------------\n",
      "Device: 104D\n",
      "Label Vector: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]...\n",
      "Vector length: 136\n",
      "--------------------------------------------------\n",
      "Device: 10CE\n",
      "Label Vector: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]...\n",
      "Vector length: 146\n",
      "--------------------------------------------------\n",
      "Device: 1210\n",
      "Label Vector: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]...\n",
      "Vector length: 143\n",
      "--------------------------------------------------\n",
      "Device: 1211\n",
      "Label Vector: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]...\n",
      "Vector length: 136\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample for device 1002:\n",
      "Label vector: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671, 1673, 1675, 1691, 1693, 1695, 3911, 3913, 3915, 3931, 3933]...\n",
      "Total measurements for device 1002: 141\n",
      "\n",
      "Summary statistics:\n",
      "Total devices: 10\n",
      "Vector lengths - Min: 136, Max: 147, Mean: 142.0\n",
      "\n",
      "All devices and their label vector lengths:\n",
      "Device 1002: 141 measurements\n",
      "Device 104D: 136 measurements\n",
      "Device 10CE: 146 measurements\n",
      "Device 1210: 143 measurements\n",
      "Device 1211: 136 measurements\n",
      "Device 1212: 141 measurements\n",
      "Device 121D: 147 measurements\n",
      "Device 1F61: 144 measurements\n",
      "Device 2005: 145 measurements\n",
      "Device 2055: 141 measurements\n"
     ]
    }
   ],
   "source": [
    "# Create the LABEL_VECTOR dataframe\n",
    "# Group by DEVICE and collect LABEL values in the order they appear\n",
    "\n",
    "label_vector_df = test_data.groupby('DEVICE')['LABEL'].apply(list).reset_index()\n",
    "label_vector_df.columns = ['DEVICE', 'LABEL_VECTOR']\n",
    "\n",
    "print(\"LABEL_VECTOR DataFrame:\")\n",
    "print(f\"Shape: {label_vector_df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "for idx, row in label_vector_df.head().iterrows():\n",
    "    print(f\"Device: {row['DEVICE']}\")\n",
    "    print(f\"Label Vector: {row['LABEL_VECTOR'][:10]}...\" if len(row['LABEL_VECTOR']) > 10 else f\"Label Vector: {row['LABEL_VECTOR']}\")\n",
    "    print(f\"Vector length: {len(row['LABEL_VECTOR'])}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\nSample for device 1002:\")\n",
    "device_1002 = label_vector_df[label_vector_df['DEVICE'] == '1002']\n",
    "if not device_1002.empty:\n",
    "    label_vector_1002 = device_1002['LABEL_VECTOR'].iloc[0]\n",
    "    print(f\"Label vector: {label_vector_1002[:20]}...\" if len(label_vector_1002) > 20 else f\"Label vector: {label_vector_1002}\")\n",
    "    print(f\"Total measurements for device 1002: {len(label_vector_1002)}\")\n",
    "else:\n",
    "    print(\"Device 1002 not found in the dataset\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(f\"Total devices: {len(label_vector_df)}\")\n",
    "vector_lengths = label_vector_df['LABEL_VECTOR'].apply(len)\n",
    "print(f\"Vector lengths - Min: {vector_lengths.min()}, Max: {vector_lengths.max()}, Mean: {vector_lengths.mean():.1f}\")\n",
    "\n",
    "# Show all devices and their vector lengths\n",
    "print(f\"\\nAll devices and their label vector lengths:\")\n",
    "for idx, row in label_vector_df.iterrows():\n",
    "    print(f\"Device {row['DEVICE']}: {len(row['LABEL_VECTOR'])} measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd66a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete LABEL_VECTOR DataFrame:\n",
      "  DEVICE                                       LABEL_VECTOR\n",
      "0   1002  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "1   104D  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "2   10CE  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "3   1210  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "4   1211  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "5   1212  [1615, 1631, 1633, 1635, 1651, 1653, 1655, 167...\n",
      "6   121D  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "7   1F61  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "8   2005  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "9   2055  [1611, 1613, 1615, 1631, 1633, 1635, 1651, 165...\n",
      "\n",
      "================================================================================\n",
      "COMPLETE LABEL_VECTOR FOR DEVICE 1002:\n",
      "================================================================================\n",
      "Device 1002 LABEL_VECTOR: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671, 1673, 1675, 1691, 1693, 1695, 3911, 3913, 3915, 3931, 3933, 3935, 3951, 3953, 3955, 4011, 4013, 4015, 4031, 4033, 4035, 4051, 4053, 4055, 4113, 4115, 4117, 4131, 4135, 4137, 4153, 4155, 4157, 4311, 4313, 4315, 4331, 4333, 4335, 4351, 4353, 4355, 4371, 4373, 4375, 4511, 4513, 4515, 4531, 4533, 4535, 4551, 4553, 4555, 4571, 4573, 4575, 4611, 4613, 4615, 4631, 4633, 4635, 4651, 4653, 4655, 4671, 4673, 4675, 4711, 4713, 4715, 4731, 4733, 4735, 4751, 4753, 4755, 4771, 4773, 4775, 5111, 5113, 5115, 5131, 5133, 5135, 5137, 5151, 5153, 5155, 5157, 5311, 5313, 5315, 5331, 5333, 5335, 5351, 5353, 5355, 5371, 5373, 5375, 5712, 5714, 5716, 5721, 5726, 6121, 6141, 6161, 6181, 6211, 6231, 6251, 6271, 6291, 6341, 6343, 6345, 6347, 6351, 6353, 6355, 6357, 61101, 61121, 61141, 62111, 62131, 62151]\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION: First 10 measurements for each device\n",
      "================================================================================\n",
      "Device 1002: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 104D: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 10CE: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 1210: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 1211: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 1212: [1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671, 1673, 1675]\n",
      "Device 121D: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 1F61: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 2005: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "Device 2055: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671]\n",
      "\n",
      "Dataframe 'label_vector_df' created successfully!\n",
      "Columns: ['DEVICE', 'LABEL_VECTOR']\n",
      "Data types: {'DEVICE': dtype('O'), 'LABEL_VECTOR': dtype('O')}\n"
     ]
    }
   ],
   "source": [
    "# Display the complete LABEL_VECTOR dataframe\n",
    "print(\"Complete LABEL_VECTOR DataFrame:\")\n",
    "print(label_vector_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE LABEL_VECTOR FOR DEVICE 1002:\")\n",
    "print(\"=\"*80)\n",
    "device_1002_vector = label_vector_df[label_vector_df['DEVICE'] == '1002']['LABEL_VECTOR'].iloc[0]\n",
    "print(f\"Device 1002 LABEL_VECTOR: {device_1002_vector}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION: First 10 measurements for each device\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in label_vector_df.iterrows():\n",
    "    device = row['DEVICE']\n",
    "    first_10_labels = row['LABEL_VECTOR'][:10]\n",
    "    print(f\"Device {device}: {first_10_labels}\")\n",
    "\n",
    "# Save the dataframe for potential future use\n",
    "print(f\"\\nDataframe 'label_vector_df' created successfully!\")\n",
    "print(f\"Columns: {list(label_vector_df.columns)}\")\n",
    "print(f\"Data types: {label_vector_df.dtypes.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6d322",
   "metadata": {},
   "source": [
    "- Dataframe with LABEL and error by label (Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb120fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered results for rho_0=55.0, alpha=4.25:\n",
      "Shape: (10, 5)\n",
      "      rho_0  alpha device  mean_error\n",
      "1630   55.0   4.25   1002        2.85\n",
      "1631   55.0   4.25   104D        2.99\n",
      "1632   55.0   4.25   10CE        3.04\n",
      "1633   55.0   4.25   1210        2.92\n",
      "1634   55.0   4.25   1211        2.93\n",
      "\n",
      "First few error lists:\n",
      "Device 1002: [2.0, 2.3, 6.1, 2.9, 2.3, 4.61, 4.56, 0.0, 3.05, 0.0]... (length: 141)\n",
      "Device 104D: [2.0, 2.3, 5.02, 2.9, 2.3, 5.02, 2.9, 3.05, 4.6, 0.0]... (length: 136)\n",
      "Device 10CE: [2.0, 2.3, 6.6, 2.0, 4.79, 5.02, 2.0, 2.3, 4.61, 0.0]... (length: 146)\n",
      "\n",
      "Devices in filtered results: ['1002', '104D', '10CE', '1210', '1211', '1212', '121D', '1F61', '2005', '2055']\n",
      "Devices in label_vector_df: ['1002', '104D', '10CE', '1210', '1211', '1212', '121D', '1F61', '2005', '2055']\n",
      "All devices match: True\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Load the nn_results_by_device.csv file\n",
    "nn_results = pd.read_csv('../output/nn_results_by_device.csv')\n",
    "\n",
    "# Filter for rho_0=55 and alpha=4.25\n",
    "filtered_results = nn_results[(nn_results['rho_0'] == 55.0) & (nn_results['alpha'] == 4.25)]\n",
    "\n",
    "print(\"Filtered results for rho_0=55.0, alpha=4.25:\")\n",
    "print(f\"Shape: {filtered_results.shape}\")\n",
    "print(filtered_results[['rho_0', 'alpha', 'device', 'mean_error']].head())\n",
    "\n",
    "# Parse the error_list strings into actual lists\n",
    "filtered_results = filtered_results.copy()\n",
    "filtered_results['error_list_parsed'] = filtered_results['error_list'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "print(f\"\\nFirst few error lists:\")\n",
    "for idx, row in filtered_results.head(3).iterrows():\n",
    "    device = row['device']\n",
    "    error_list = row['error_list_parsed']\n",
    "    print(f\"Device {device}: {error_list[:10]}... (length: {len(error_list)})\")\n",
    "\n",
    "# Verify we have all 10 devices\n",
    "print(f\"\\nDevices in filtered results: {sorted(filtered_results['device'].unique())}\")\n",
    "print(f\"Devices in label_vector_df: {sorted(label_vector_df['DEVICE'].unique())}\")\n",
    "\n",
    "# Check if all devices match\n",
    "devices_match = set(filtered_results['device'].unique()) == set(label_vector_df['DEVICE'].unique())\n",
    "print(f\"All devices match: {devices_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a78c4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete!\n",
      "Number of unique labels: 148\n",
      "\n",
      "Final LABEL and MEAN_ERROR DataFrame:\n",
      "Shape: (148, 2)\n",
      "\n",
      "First 10 rows:\n",
      "   LABEL  MEAN_ERROR\n",
      "0   1611    1.777778\n",
      "1   1613    2.300000\n",
      "2   1615    5.510000\n",
      "3   1631    2.050000\n",
      "4   1633    3.122000\n",
      "5   1635    5.154000\n",
      "6   1651    1.726000\n",
      "7   1653    2.509000\n",
      "8   1655    4.724000\n",
      "9   1671    0.000000\n",
      "\n",
      "Last 10 rows:\n",
      "     LABEL  MEAN_ERROR\n",
      "138   6351    1.473000\n",
      "139   6353    1.392000\n",
      "140   6355    2.173333\n",
      "141   6357    2.307000\n",
      "142  61101    2.590000\n",
      "143  61121    1.870000\n",
      "144  61141    2.700000\n",
      "145  62111    1.492000\n",
      "146  62131    2.422000\n",
      "147  62151    2.280000\n",
      "\n",
      "Summary statistics for MEAN_ERROR:\n",
      "count    148.000000\n",
      "mean       2.899210\n",
      "std        1.301874\n",
      "min        0.000000\n",
      "25%        2.190250\n",
      "50%        2.725278\n",
      "75%        3.736083\n",
      "max        6.575000\n",
      "Name: MEAN_ERROR, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from device to error_list\n",
    "device_to_error_list = dict(zip(filtered_results['device'], filtered_results['error_list_parsed']))\n",
    "\n",
    "# Create a dictionary to collect all errors for each label\n",
    "label_errors = {}\n",
    "\n",
    "# Iterate through each device and its label vector\n",
    "for idx, row in label_vector_df.iterrows():\n",
    "    device = row['DEVICE']\n",
    "    label_vector = row['LABEL_VECTOR']\n",
    "    error_list = device_to_error_list[device]\n",
    "    \n",
    "    # Check if the lengths match\n",
    "    if len(label_vector) != len(error_list):\n",
    "        print(f\"WARNING: Length mismatch for device {device}: labels={len(label_vector)}, errors={len(error_list)}\")\n",
    "        continue\n",
    "    \n",
    "    # Map each label to its corresponding error\n",
    "    for label, error in zip(label_vector, error_list):\n",
    "        if label not in label_errors:\n",
    "            label_errors[label] = []\n",
    "        label_errors[label].append(error)\n",
    "\n",
    "print(f\"Processing complete!\")\n",
    "print(f\"Number of unique labels: {len(label_errors)}\")\n",
    "\n",
    "# Create the final dataframe with LABEL and MEAN_ERROR\n",
    "labels = []\n",
    "mean_errors = []\n",
    "\n",
    "for label in sorted(label_errors.keys()):\n",
    "    errors = label_errors[label]\n",
    "    mean_error = np.mean(errors)\n",
    "    labels.append(label)\n",
    "    mean_errors.append(mean_error)\n",
    "\n",
    "# Create the final dataframe\n",
    "label_mean_error_df = pd.DataFrame({\n",
    "    'LABEL': labels,\n",
    "    'MEAN_ERROR': mean_errors\n",
    "})\n",
    "\n",
    "print(f\"\\nFinal LABEL and MEAN_ERROR DataFrame:\")\n",
    "print(f\"Shape: {label_mean_error_df.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(label_mean_error_df.head(10))\n",
    "\n",
    "print(f\"\\nLast 10 rows:\")\n",
    "print(label_mean_error_df.tail(10))\n",
    "\n",
    "print(f\"\\nSummary statistics for MEAN_ERROR:\")\n",
    "print(label_mean_error_df['MEAN_ERROR'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646690d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICATION: Calculation for LABEL 1611\n",
      "============================================================\n",
      "Device 1002: Position 0, Error = 2.0\n",
      "Device 104D: Position 0, Error = 2.0\n",
      "Device 10CE: Position 0, Error = 2.0\n",
      "Device 1210: Position 0, Error = 2.0\n",
      "Device 1211: Position 0, Error = 2.0\n",
      "Device 121D: Position 0, Error = 2.0\n",
      "Device 1F61: Position 0, Error = 2.0\n",
      "Device 2005: Position 0, Error = 2.0\n",
      "Device 2055: Position 0, Error = 0.0\n",
      "\n",
      "Calculated mean error for LABEL 1611: 1.777778\n",
      "DataFrame mean error for LABEL 1611: 1.777778\n",
      "Match: True\n",
      "\n",
      "============================================================\n",
      "FINAL DATAFRAME SAMPLE:\n",
      "============================================================\n",
      "LABEL and MEAN_ERROR DataFrame (first 20 rows):\n",
      " LABEL  MEAN_ERROR\n",
      "  1611    1.777778\n",
      "  1613    2.300000\n",
      "  1615    5.510000\n",
      "  1631    2.050000\n",
      "  1633    3.122000\n",
      "  1635    5.154000\n",
      "  1651    1.726000\n",
      "  1653    2.509000\n",
      "  1655    4.724000\n",
      "  1671    0.000000\n",
      "  1673    2.645000\n",
      "  1675    4.228000\n",
      "  1691    1.466000\n",
      "  1693    2.807000\n",
      "  1695    3.994000\n",
      "  3911    0.630000\n",
      "  3913    2.192000\n",
      "  3915    3.775000\n",
      "  3931    1.970000\n",
      "  3933    2.852000\n",
      "\n",
      "============================================================\n",
      "SUMMARY:\n",
      "============================================================\n",
      "✓ Successfully created LABEL and MEAN_ERROR dataframe\n",
      "✓ Total unique labels: 148\n",
      "✓ Mean error range: 0.000 to 6.575\n",
      "✓ Parameters used: rho_0 = 55.0, alpha = 4.25\n",
      "✓ All 10 devices included in calculations\n"
     ]
    }
   ],
   "source": [
    "# Detailed verification - show the calculation for LABEL 1611 as an example\n",
    "example_label = 1611\n",
    "print(f\"VERIFICATION: Calculation for LABEL {example_label}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find all devices that have this label and their corresponding errors\n",
    "example_errors = []\n",
    "for idx, row in label_vector_df.iterrows():\n",
    "    device = row['DEVICE']\n",
    "    label_vector = row['LABEL_VECTOR']\n",
    "    error_list = device_to_error_list[device]\n",
    "    \n",
    "    # Find the position of the example label in this device's label vector\n",
    "    if example_label in label_vector:\n",
    "        label_position = label_vector.index(example_label)\n",
    "        error_value = error_list[label_position]\n",
    "        example_errors.append((device, error_value))\n",
    "        print(f\"Device {device}: Position {label_position}, Error = {error_value}\")\n",
    "\n",
    "calculated_mean = np.mean([error for _, error in example_errors])\n",
    "print(f\"\\nCalculated mean error for LABEL {example_label}: {calculated_mean:.6f}\")\n",
    "\n",
    "# Verify with our dataframe\n",
    "df_mean = label_mean_error_df[label_mean_error_df['LABEL'] == example_label]['MEAN_ERROR'].iloc[0]\n",
    "print(f\"DataFrame mean error for LABEL {example_label}: {df_mean:.6f}\")\n",
    "print(f\"Match: {abs(calculated_mean - df_mean) < 1e-10}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL DATAFRAME SAMPLE:\")\n",
    "print(\"=\"*60)\n",
    "print(\"LABEL and MEAN_ERROR DataFrame (first 20 rows):\")\n",
    "print(label_mean_error_df.head(20).to_string(index=False))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Successfully created LABEL and MEAN_ERROR dataframe\")\n",
    "print(f\"✓ Total unique labels: {len(label_mean_error_df)}\")\n",
    "print(f\"✓ Mean error range: {label_mean_error_df['MEAN_ERROR'].min():.3f} to {label_mean_error_df['MEAN_ERROR'].max():.3f}\")\n",
    "print(f\"✓ Parameters used: rho_0 = 55.0, alpha = 4.25\")\n",
    "print(f\"✓ All 10 devices included in calculations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4718ddb",
   "metadata": {},
   "source": [
    "- Save the dataframe into output/  (Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b64c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully saved dataframe to: ../output/nn_error_by_label.csv\n",
      "✓ File contains 148 rows and 2 columns\n",
      "✓ Columns: ['LABEL', 'MEAN_ERROR']\n",
      "\n",
      "Verification - file read successfully:\n",
      "Shape: (148, 2)\n",
      "First 5 rows:\n",
      "   LABEL  MEAN_ERROR\n",
      "0   1611    1.777778\n",
      "1   1613    2.300000\n",
      "2   1615    5.510000\n",
      "3   1631    2.050000\n",
      "4   1633    3.122000\n",
      "\n",
      "Data types:\n",
      "LABEL           int64\n",
      "MEAN_ERROR    float64\n",
      "dtype: object\n",
      "\n",
      "Data integrity check: False\n",
      "\n",
      "============================================================\n",
      "FILE SAVED SUCCESSFULLY: nn_error_by_label.csv\n",
      "Location: /home/braulio/thesis/output/nn_error_by_label.csv\n",
      "Contents: LABEL and MEAN_ERROR for rho_0=55.0, alpha=4.25\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save the label_mean_error_df dataframe to the output directory\n",
    "output_file = '../output/nn_error_by_label.csv'\n",
    "\n",
    "# Save the dataframe\n",
    "label_mean_error_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Successfully saved dataframe to: {output_file}\")\n",
    "print(f\"✓ File contains {len(label_mean_error_df)} rows and {len(label_mean_error_df.columns)} columns\")\n",
    "print(f\"✓ Columns: {list(label_mean_error_df.columns)}\")\n",
    "\n",
    "# Verify the file was saved correctly by reading it back\n",
    "try:\n",
    "    verification_df = pd.read_csv(output_file)\n",
    "    print(f\"\\nVerification - file read successfully:\")\n",
    "    print(f\"Shape: {verification_df.shape}\")\n",
    "    print(f\"First 5 rows:\")\n",
    "    print(verification_df.head())\n",
    "    print(f\"\\nData types:\")\n",
    "    print(verification_df.dtypes)\n",
    "    \n",
    "    # Check if the data matches\n",
    "    data_matches = verification_df.equals(label_mean_error_df)\n",
    "    print(f\"\\nData integrity check: {data_matches}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading back the file: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FILE SAVED SUCCESSFULLY: nn_error_by_label.csv\")\n",
    "print(f\"Location: /path/to/thesis/output/nn_error_by_label.csv\")\n",
    "print(f\"Contents: LABEL and MEAN_ERROR for rho_0=55.0, alpha=4.25\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b1558",
   "metadata": {},
   "source": [
    "- Dataframe with LABEL and error by label (SLSQP(+))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157c8659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered SLSQP(+) results for rho_0=55.0, alpha=4.25:\n",
      "Shape: (10, 5)\n",
      "      rho_0  alpha device  mean_error\n",
      "1390   55.0   4.25   1002        2.75\n",
      "1391   55.0   4.25   104D        2.74\n",
      "1392   55.0   4.25   10CE        2.61\n",
      "1393   55.0   4.25   1210        2.63\n",
      "1394   55.0   4.25   1211        2.74\n",
      "\n",
      "First few SLSQP(+) error lists:\n",
      "Device 1002: [1.32, 1.59, 6.57, 3.36, 3.08, 5.03, 3.9, 1.94, 3.97, 0.73]... (length: 141)\n",
      "Device 104D: [2.03, 0.46, 5.19, 3.1, 3.7, 4.68, 3.65, 4.97, 4.02, 2.0]... (length: 136)\n",
      "Device 10CE: [1.74, 1.87, 6.03, 0.46, 3.95, 5.39, 2.06, 3.67, 3.36, 0.5]... (length: 146)\n",
      "\n",
      "Devices in filtered SLSQP(+) results: ['1002', '104D', '10CE', '1210', '1211', '1212', '121D', '1F61', '2005', '2055']\n",
      "Devices in label_vector_df: ['1002', '104D', '10CE', '1210', '1211', '1212', '121D', '1F61', '2005', '2055']\n",
      "All devices match: True\n",
      "\n",
      "Mean errors comparison (same parameters: rho_0=55.0, alpha=4.25):\n",
      "============================================================\n",
      "DEVICE    | Nearest Neighbor | SLSQP(+)    | Difference\n",
      "============================================================\n",
      "1002     |            2.85 |       2.75 |     +0.10\n",
      "104D     |            2.99 |       2.74 |     +0.25\n",
      "10CE     |            3.04 |       2.61 |     +0.43\n",
      "1210     |            2.92 |       2.63 |     +0.29\n",
      "1211     |            2.93 |       2.74 |     +0.19\n",
      "1212     |            3.03 |       2.73 |     +0.30\n",
      "121D     |            2.82 |       2.58 |     +0.24\n",
      "1F61     |            2.78 |       2.61 |     +0.17\n",
      "2005     |            2.79 |       2.55 |     +0.24\n",
      "2055     |            2.85 |       2.54 |     +0.31\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the optimized_results_by_device.csv file (SLSQP(+) results)\n",
    "optimized_results = pd.read_csv('../output/optimized_results_by_device.csv')\n",
    "\n",
    "# Filter for rho_0=55 and alpha=4.25 (same parameters as Nearest Neighbor)\n",
    "filtered_optimized_results = optimized_results[(optimized_results['rho_0'] == 55.0) & (optimized_results['alpha'] == 4.25)]\n",
    "\n",
    "print(\"Filtered SLSQP(+) results for rho_0=55.0, alpha=4.25:\")\n",
    "print(f\"Shape: {filtered_optimized_results.shape}\")\n",
    "print(filtered_optimized_results[['rho_0', 'alpha', 'device', 'mean_error']].head())\n",
    "\n",
    "# Parse the error_list strings into actual lists\n",
    "filtered_optimized_results = filtered_optimized_results.copy()\n",
    "filtered_optimized_results['error_list_parsed'] = filtered_optimized_results['error_list'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "print(f\"\\nFirst few SLSQP(+) error lists:\")\n",
    "for idx, row in filtered_optimized_results.head(3).iterrows():\n",
    "    device = row['device']\n",
    "    error_list = row['error_list_parsed']\n",
    "    print(f\"Device {device}: {error_list[:10]}... (length: {len(error_list)})\")\n",
    "\n",
    "# Verify we have all 10 devices\n",
    "print(f\"\\nDevices in filtered SLSQP(+) results: {sorted(filtered_optimized_results['device'].unique())}\")\n",
    "print(f\"Devices in label_vector_df: {sorted(label_vector_df['DEVICE'].unique())}\")\n",
    "\n",
    "# Check if all devices match\n",
    "devices_match_slsqp = set(filtered_optimized_results['device'].unique()) == set(label_vector_df['DEVICE'].unique())\n",
    "print(f\"All devices match: {devices_match_slsqp}\")\n",
    "\n",
    "# Compare mean errors between algorithms\n",
    "print(f\"\\nMean errors comparison (same parameters: rho_0=55.0, alpha=4.25):\")\n",
    "print(\"=\" * 60)\n",
    "print(\"DEVICE    | Nearest Neighbor | SLSQP(+)    | Difference\")\n",
    "print(\"=\" * 60)\n",
    "for device in sorted(filtered_results['device'].unique()):\n",
    "    nn_error = filtered_results[filtered_results['device'] == device]['mean_error'].iloc[0]\n",
    "    slsqp_error = filtered_optimized_results[filtered_optimized_results['device'] == device]['mean_error'].iloc[0]\n",
    "    diff = nn_error - slsqp_error\n",
    "    print(f\"{device:8} | {nn_error:15.2f} | {slsqp_error:10.2f} | {diff:+9.2f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2f3072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLSQP(+) processing complete!\n",
      "Number of unique labels: 148\n",
      "\n",
      "Final SLSQP(+) LABEL and MEAN_ERROR DataFrame:\n",
      "Shape: (148, 2)\n",
      "\n",
      "First 10 rows:\n",
      "   LABEL  MEAN_ERROR\n",
      "0   1611    1.656667\n",
      "1   1613    2.224444\n",
      "2   1615    5.591000\n",
      "3   1631    2.009000\n",
      "4   1633    3.473000\n",
      "5   1635    4.741000\n",
      "6   1651    2.740000\n",
      "7   1653    3.271000\n",
      "8   1655    4.405000\n",
      "9   1671    0.984000\n",
      "\n",
      "Last 10 rows:\n",
      "     LABEL  MEAN_ERROR\n",
      "138   6351    1.952000\n",
      "139   6353    2.566000\n",
      "140   6355    2.445556\n",
      "141   6357    2.060000\n",
      "142  61101    1.938000\n",
      "143  61121    1.445000\n",
      "144  61141    2.662000\n",
      "145  62111    1.074000\n",
      "146  62131    2.373000\n",
      "147  62151    3.154000\n",
      "\n",
      "Summary statistics for SLSQP(+) MEAN_ERROR:\n",
      "count    148.000000\n",
      "mean       2.645840\n",
      "std        1.175014\n",
      "min        0.689000\n",
      "25%        1.789000\n",
      "50%        2.417500\n",
      "75%        3.262750\n",
      "max        6.119000\n",
      "Name: MEAN_ERROR, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from device to error_list for SLSQP(+)\n",
    "device_to_error_list_slsqp = dict(zip(filtered_optimized_results['device'], filtered_optimized_results['error_list_parsed']))\n",
    "\n",
    "# Create a dictionary to collect all errors for each label (SLSQP+)\n",
    "label_errors_slsqp = {}\n",
    "\n",
    "# Iterate through each device and its label vector\n",
    "for idx, row in label_vector_df.iterrows():\n",
    "    device = row['DEVICE']\n",
    "    label_vector = row['LABEL_VECTOR']\n",
    "    error_list = device_to_error_list_slsqp[device]\n",
    "    \n",
    "    # Check if the lengths match\n",
    "    if len(label_vector) != len(error_list):\n",
    "        print(f\"WARNING: Length mismatch for device {device}: labels={len(label_vector)}, errors={len(error_list)}\")\n",
    "        continue\n",
    "    \n",
    "    # Map each label to its corresponding error\n",
    "    for label, error in zip(label_vector, error_list):\n",
    "        if label not in label_errors_slsqp:\n",
    "            label_errors_slsqp[label] = []\n",
    "        label_errors_slsqp[label].append(error)\n",
    "\n",
    "print(f\"SLSQP(+) processing complete!\")\n",
    "print(f\"Number of unique labels: {len(label_errors_slsqp)}\")\n",
    "\n",
    "# Create the final dataframe with LABEL and MEAN_ERROR for SLSQP(+)\n",
    "labels_slsqp = []\n",
    "mean_errors_slsqp = []\n",
    "\n",
    "for label in sorted(label_errors_slsqp.keys()):\n",
    "    errors = label_errors_slsqp[label]\n",
    "    mean_error = np.mean(errors)\n",
    "    labels_slsqp.append(label)\n",
    "    mean_errors_slsqp.append(mean_error)\n",
    "\n",
    "# Create the final dataframe for SLSQP(+)\n",
    "label_mean_error_slsqp_df = pd.DataFrame({\n",
    "    'LABEL': labels_slsqp,\n",
    "    'MEAN_ERROR': mean_errors_slsqp\n",
    "})\n",
    "\n",
    "print(f\"\\nFinal SLSQP(+) LABEL and MEAN_ERROR DataFrame:\")\n",
    "print(f\"Shape: {label_mean_error_slsqp_df.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(label_mean_error_slsqp_df.head(10))\n",
    "\n",
    "print(f\"\\nLast 10 rows:\")\n",
    "print(label_mean_error_slsqp_df.tail(10))\n",
    "\n",
    "print(f\"\\nSummary statistics for SLSQP(+) MEAN_ERROR:\")\n",
    "print(label_mean_error_slsqp_df['MEAN_ERROR'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ad23ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICATION: Calculation for LABEL 1611 (SLSQP+)\n",
      "============================================================\n",
      "Device 1002: Position 0, Error = 1.32\n",
      "Device 104D: Position 0, Error = 2.03\n",
      "Device 10CE: Position 0, Error = 1.74\n",
      "Device 1210: Position 0, Error = 2.33\n",
      "Device 1211: Position 0, Error = 2.07\n",
      "Device 121D: Position 0, Error = 1.08\n",
      "Device 1F61: Position 0, Error = 1.19\n",
      "Device 2005: Position 0, Error = 1.15\n",
      "Device 2055: Position 0, Error = 2.0\n",
      "\n",
      "Calculated mean error for LABEL 1611 (SLSQP+): 1.656667\n",
      "DataFrame mean error for LABEL 1611 (SLSQP+): 1.656667\n",
      "Match: True\n",
      "\n",
      "================================================================================\n",
      "ALGORITHM COMPARISON FOR LABEL 1611:\n",
      "================================================================================\n",
      "Nearest Neighbor mean error: 1.777778\n",
      "SLSQP(+) mean error:         1.656667\n",
      "Improvement:                 0.121111 (+6.81%)\n",
      "\n",
      "================================================================================\n",
      "OVERALL COMPARISON BETWEEN ALGORITHMS:\n",
      "================================================================================\n",
      "Number of labels compared: 148\n",
      "\n",
      "Overall statistics:\n",
      "Mean error - Nearest Neighbor: 2.8992\n",
      "Mean error - SLSQP(+):         2.6458\n",
      "Mean improvement:              0.2534\n",
      "Mean improvement percentage:   -inf%\n",
      "\n",
      "Improvement distribution:\n",
      "Labels where SLSQP(+) is better: 98 (66.2%)\n",
      "Labels where NN is better:       50 (33.8%)\n",
      "Labels where they're equal:      0 (0.0%)\n",
      "\n",
      "Top 10 labels with best SLSQP(+) improvement:\n",
      " LABEL  MEAN_ERROR_NN  MEAN_ERROR_SLSQP  IMPROVEMENT  IMPROVEMENT_PCT\n",
      "  4355          4.684             2.815        1.869           39.902\n",
      "  5311          3.091             1.303        1.788           57.845\n",
      "  4653          4.306             2.572        1.734           40.269\n",
      "  4511          4.006             2.308        1.698           42.386\n",
      "  4531          3.441             1.784        1.657           48.155\n",
      "  4315          4.766             3.120        1.646           34.536\n",
      "  4373          3.444             1.799        1.645           47.764\n",
      "  4375          4.551             2.977        1.574           34.586\n",
      "  4535          4.645             3.077        1.568           33.757\n",
      "  4333          2.530             0.977        1.553           61.383\n"
     ]
    }
   ],
   "source": [
    "# Detailed verification and comparison between algorithms\n",
    "example_label = 1611\n",
    "print(f\"VERIFICATION: Calculation for LABEL {example_label} (SLSQP+)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find all devices that have this label and their corresponding errors for SLSQP+\n",
    "example_errors_slsqp = []\n",
    "for idx, row in label_vector_df.iterrows():\n",
    "    device = row['DEVICE']\n",
    "    label_vector = row['LABEL_VECTOR']\n",
    "    error_list = device_to_error_list_slsqp[device]\n",
    "    \n",
    "    # Find the position of the example label in this device's label vector\n",
    "    if example_label in label_vector:\n",
    "        label_position = label_vector.index(example_label)\n",
    "        error_value = error_list[label_position]\n",
    "        example_errors_slsqp.append((device, error_value))\n",
    "        print(f\"Device {device}: Position {label_position}, Error = {error_value}\")\n",
    "\n",
    "calculated_mean_slsqp = np.mean([error for _, error in example_errors_slsqp])\n",
    "print(f\"\\nCalculated mean error for LABEL {example_label} (SLSQP+): {calculated_mean_slsqp:.6f}\")\n",
    "\n",
    "# Verify with our dataframe\n",
    "df_mean_slsqp = label_mean_error_slsqp_df[label_mean_error_slsqp_df['LABEL'] == example_label]['MEAN_ERROR'].iloc[0]\n",
    "print(f\"DataFrame mean error for LABEL {example_label} (SLSQP+): {df_mean_slsqp:.6f}\")\n",
    "print(f\"Match: {abs(calculated_mean_slsqp - df_mean_slsqp) < 1e-10}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"ALGORITHM COMPARISON FOR LABEL 1611:\")\n",
    "print(\"=\"*80)\n",
    "nn_mean = label_mean_error_df[label_mean_error_df['LABEL'] == example_label]['MEAN_ERROR'].iloc[0]\n",
    "slsqp_mean = label_mean_error_slsqp_df[label_mean_error_slsqp_df['LABEL'] == example_label]['MEAN_ERROR'].iloc[0]\n",
    "improvement = nn_mean - slsqp_mean\n",
    "improvement_pct = (improvement / nn_mean) * 100\n",
    "\n",
    "print(f\"Nearest Neighbor mean error: {nn_mean:.6f}\")\n",
    "print(f\"SLSQP(+) mean error:         {slsqp_mean:.6f}\")\n",
    "print(f\"Improvement:                 {improvement:.6f} ({improvement_pct:+.2f}%)\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL COMPARISON BETWEEN ALGORITHMS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Merge the dataframes for comparison\n",
    "comparison_df = pd.merge(label_mean_error_df, label_mean_error_slsqp_df, \n",
    "                        on='LABEL', suffixes=('_NN', '_SLSQP'))\n",
    "comparison_df['IMPROVEMENT'] = comparison_df['MEAN_ERROR_NN'] - comparison_df['MEAN_ERROR_SLSQP']\n",
    "comparison_df['IMPROVEMENT_PCT'] = (comparison_df['IMPROVEMENT'] / comparison_df['MEAN_ERROR_NN']) * 100\n",
    "\n",
    "print(f\"Number of labels compared: {len(comparison_df)}\")\n",
    "print(f\"\\nOverall statistics:\")\n",
    "print(f\"Mean error - Nearest Neighbor: {comparison_df['MEAN_ERROR_NN'].mean():.4f}\")\n",
    "print(f\"Mean error - SLSQP(+):         {comparison_df['MEAN_ERROR_SLSQP'].mean():.4f}\")\n",
    "print(f\"Mean improvement:              {comparison_df['IMPROVEMENT'].mean():.4f}\")\n",
    "print(f\"Mean improvement percentage:   {comparison_df['IMPROVEMENT_PCT'].mean():.2f}%\")\n",
    "\n",
    "print(f\"\\nImprovement distribution:\")\n",
    "print(f\"Labels where SLSQP(+) is better: {(comparison_df['IMPROVEMENT'] > 0).sum()} ({(comparison_df['IMPROVEMENT'] > 0).mean()*100:.1f}%)\")\n",
    "print(f\"Labels where NN is better:       {(comparison_df['IMPROVEMENT'] < 0).sum()} ({(comparison_df['IMPROVEMENT'] < 0).mean()*100:.1f}%)\")\n",
    "print(f\"Labels where they're equal:      {(comparison_df['IMPROVEMENT'] == 0).sum()} ({(comparison_df['IMPROVEMENT'] == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTop 10 labels with best SLSQP(+) improvement:\")\n",
    "top_improvements = comparison_df.nlargest(10, 'IMPROVEMENT')[['LABEL', 'MEAN_ERROR_NN', 'MEAN_ERROR_SLSQP', 'IMPROVEMENT', 'IMPROVEMENT_PCT']]\n",
    "print(top_improvements.to_string(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0efb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully saved SLSQP(+) dataframe to: ../output/slsqp_error_by_label.csv\n",
      "✓ File contains 148 rows and 2 columns\n",
      "✓ Columns: ['LABEL', 'MEAN_ERROR']\n",
      "\n",
      "Verification - SLSQP(+) file read successfully:\n",
      "Shape: (148, 2)\n",
      "First 5 rows:\n",
      "   LABEL  MEAN_ERROR\n",
      "0   1611    1.656667\n",
      "1   1613    2.224444\n",
      "2   1615    5.591000\n",
      "3   1631    2.009000\n",
      "4   1633    3.473000\n",
      "\n",
      "Data integrity check: False\n",
      "\n",
      "============================================================\n",
      "FILE SAVED SUCCESSFULLY: slsqp_error_by_label.csv\n",
      "Location: /home/braulio/thesis/output/slsqp_error_by_label.csv\n",
      "Contents: LABEL and MEAN_ERROR for SLSQP(+) rho_0=55.0, alpha=4.25\n",
      "============================================================\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF CREATED FILES:\n",
      "================================================================================\n",
      "1. nn_error_by_label.csv    - Nearest Neighbor algorithm results\n",
      "2. slsqp_error_by_label.csv - SLSQP(+) algorithm results\n",
      "Both files contain:\n",
      "- 148 unique labels (room/location identifiers)\n",
      "- Mean positioning errors for rho_0=55.0, alpha=4.25\n",
      "- Calculated across all 10 devices\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save the SLSQP(+) label_mean_error_slsqp_df dataframe to the output directory\n",
    "output_file_slsqp = '../output/slsqp_error_by_label.csv'\n",
    "\n",
    "# Save the dataframe\n",
    "label_mean_error_slsqp_df.to_csv(output_file_slsqp, index=False)\n",
    "\n",
    "print(f\"✓ Successfully saved SLSQP(+) dataframe to: {output_file_slsqp}\")\n",
    "print(f\"✓ File contains {len(label_mean_error_slsqp_df)} rows and {len(label_mean_error_slsqp_df.columns)} columns\")\n",
    "print(f\"✓ Columns: {list(label_mean_error_slsqp_df.columns)}\")\n",
    "\n",
    "# Verify the file was saved correctly by reading it back\n",
    "try:\n",
    "    verification_df_slsqp = pd.read_csv(output_file_slsqp)\n",
    "    print(f\"\\nVerification - SLSQP(+) file read successfully:\")\n",
    "    print(f\"Shape: {verification_df_slsqp.shape}\")\n",
    "    print(f\"First 5 rows:\")\n",
    "    print(verification_df_slsqp.head())\n",
    "    \n",
    "    # Check if the data matches\n",
    "    data_matches_slsqp = verification_df_slsqp.equals(label_mean_error_slsqp_df)\n",
    "    print(f\"\\nData integrity check: {data_matches_slsqp}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading back the file: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FILE SAVED SUCCESSFULLY: slsqp_error_by_label.csv\")\n",
    "print(f\"Location: /home/braulio/thesis/output/slsqp_error_by_label.csv\")\n",
    "print(f\"Contents: LABEL and MEAN_ERROR for SLSQP(+) rho_0=55.0, alpha=4.25\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY OF CREATED FILES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. nn_error_by_label.csv    - Nearest Neighbor algorithm results\")\n",
    "print(\"2. slsqp_error_by_label.csv - SLSQP(+) algorithm results\")\n",
    "print(\"Both files contain:\")\n",
    "print(\"- 148 unique labels (room/location identifiers)\")\n",
    "print(\"- Mean positioning errors for rho_0=55.0, alpha=4.25\")\n",
    "print(\"- Calculated across all 10 devices\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21dc7da",
   "metadata": {},
   "source": [
    "- Dataframe with LABEL and ROOM columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c55c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique labels found: 148\n",
      "Label range: 1611 to 62151\n",
      "\n",
      "Label prefix to room mapping rules:\n",
      "  Labels starting with '16' → Room 1\n",
      "  Labels starting with '41' → Room 2\n",
      "  Labels starting with '57' → Room 3\n",
      "  Labels starting with '40' → Room 4\n",
      "  Labels starting with '53' → Room 5\n",
      "  Labels starting with '39' → Room 6\n",
      "  Labels starting with '47' → Room 7\n",
      "  Labels starting with '51' → Room 8\n",
      "  Labels starting with '45' → Room 9\n",
      "  Labels starting with '43' → Room 10\n",
      "  Labels starting with '46' → Room 11\n",
      "  Labels starting with '63' → Hall 1\n",
      "  Labels starting with '61' → Hall 2\n",
      "  Labels starting with '62' → Hall 3\n",
      "\n",
      "Label to Room DataFrame created:\n",
      "Shape: (148, 2)\n",
      "\n",
      "First 20 rows:\n",
      "    LABEL    ROOM\n",
      "0    1611  Room 1\n",
      "1    1613  Room 1\n",
      "2    1615  Room 1\n",
      "3    1631  Room 1\n",
      "4    1633  Room 1\n",
      "5    1635  Room 1\n",
      "6    1651  Room 1\n",
      "7    1653  Room 1\n",
      "8    1655  Room 1\n",
      "9    1671  Room 1\n",
      "10   1673  Room 1\n",
      "11   1675  Room 1\n",
      "12   1691  Room 1\n",
      "13   1693  Room 1\n",
      "14   1695  Room 1\n",
      "15   3911  Room 6\n",
      "16   3913  Room 6\n",
      "17   3915  Room 6\n",
      "18   3931  Room 6\n",
      "19   3933  Room 6\n",
      "\n",
      "Distribution by ROOM:\n",
      "ROOM\n",
      "Hall 1      8\n",
      "Hall 2      7\n",
      "Hall 3      8\n",
      "Room 1     15\n",
      "Room 10    12\n",
      "Room 11    12\n",
      "Room 2     12\n",
      "Room 3      8\n",
      "Room 4      9\n",
      "Room 5     12\n",
      "Room 6      9\n",
      "Room 7     12\n",
      "Room 8     12\n",
      "Room 9     12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ All labels successfully mapped to rooms!\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with LABEL and ROOM columns based on label prefix rules\n",
    "\n",
    "# First, get all unique labels from our previous analysis\n",
    "all_labels = sorted(label_mean_error_df['LABEL'].unique())\n",
    "\n",
    "print(f\"Total unique labels found: {len(all_labels)}\")\n",
    "print(f\"Label range: {min(all_labels)} to {max(all_labels)}\")\n",
    "\n",
    "# Define the mapping rules from label prefix to room\n",
    "label_to_room_rules = {\n",
    "    '16': 'Room 1',\n",
    "    '41': 'Room 2', \n",
    "    '57': 'Room 3',\n",
    "    '40': 'Room 4',\n",
    "    '53': 'Room 5',\n",
    "    '39': 'Room 6',\n",
    "    '47': 'Room 7',\n",
    "    '51': 'Room 8',\n",
    "    '45': 'Room 9',\n",
    "    '43': 'Room 10',\n",
    "    '46': 'Room 11',\n",
    "    '63': 'Hall 1',\n",
    "    '61': 'Hall 2',\n",
    "    '62': 'Hall 3'\n",
    "}\n",
    "\n",
    "print(f\"\\nLabel prefix to room mapping rules:\")\n",
    "for prefix, room in label_to_room_rules.items():\n",
    "    print(f\"  Labels starting with '{prefix}' → {room}\")\n",
    "\n",
    "# Function to determine room based on label\n",
    "def get_room_from_label(label):\n",
    "    \"\"\"\n",
    "    Determine the room based on the label prefix according to the specified rules.\n",
    "    \"\"\"\n",
    "    label_str = str(label)\n",
    "    \n",
    "    # Check each prefix rule\n",
    "    for prefix, room in label_to_room_rules.items():\n",
    "        if label_str.startswith(prefix):\n",
    "            return room\n",
    "    \n",
    "    # If no rule matches, return 'Unknown'\n",
    "    return 'Unknown'\n",
    "\n",
    "# Create the LABEL and ROOM dataframe\n",
    "labels = []\n",
    "rooms = []\n",
    "\n",
    "for label in all_labels:\n",
    "    room = get_room_from_label(label)\n",
    "    labels.append(label)\n",
    "    rooms.append(room)\n",
    "\n",
    "# Create the dataframe\n",
    "label_room_df = pd.DataFrame({\n",
    "    'LABEL': labels,\n",
    "    'ROOM': rooms\n",
    "})\n",
    "\n",
    "print(f\"\\nLabel to Room DataFrame created:\")\n",
    "print(f\"Shape: {label_room_df.shape}\")\n",
    "\n",
    "# Display first 20 rows\n",
    "print(f\"\\nFirst 20 rows:\")\n",
    "print(label_room_df.head(20))\n",
    "\n",
    "# Show distribution by room\n",
    "print(f\"\\nDistribution by ROOM:\")\n",
    "room_counts = label_room_df['ROOM'].value_counts().sort_index()\n",
    "print(room_counts)\n",
    "\n",
    "# Check for any unknown labels\n",
    "unknown_labels = label_room_df[label_room_df['ROOM'] == 'Unknown']\n",
    "if len(unknown_labels) > 0:\n",
    "    print(f\"\\nLabels that don't match any rule (Unknown):\")\n",
    "    print(unknown_labels['LABEL'].tolist())\n",
    "else:\n",
    "    print(f\"\\n✓ All labels successfully mapped to rooms!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a13e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DETAILED ROOM ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Sample labels for each room:\n",
      "Hall 1   ( 8 labels): [6341, 6343, 6345, 6347, 6351]\n",
      "Hall 2   ( 7 labels): [6121, 6141, 6161, 6181, 61101]\n",
      "Hall 3   ( 8 labels): [6211, 6231, 6251, 6271, 6291]\n",
      "Room 1   (15 labels): [1611, 1613, 1615, 1631, 1633]\n",
      "Room 10  (12 labels): [4311, 4313, 4315, 4331, 4333]\n",
      "Room 11  (12 labels): [4611, 4613, 4615, 4631, 4633]\n",
      "Room 2   (12 labels): [4111, 4113, 4115, 4117, 4131]\n",
      "Room 3   ( 8 labels): [5711, 5712, 5714, 5716, 5721]\n",
      "Room 4   ( 9 labels): [4011, 4013, 4015, 4031, 4033]\n",
      "Room 5   (12 labels): [5311, 5313, 5315, 5331, 5333]\n",
      "Room 6   ( 9 labels): [3911, 3913, 3915, 3931, 3933]\n",
      "Room 7   (12 labels): [4711, 4713, 4715, 4731, 4733]\n",
      "Room 8   (12 labels): [5111, 5113, 5115, 5117, 5131]\n",
      "Room 9   (12 labels): [4511, 4513, 4515, 4531, 4533]\n",
      "\n",
      "================================================================================\n",
      "COMPLETE ROOM BREAKDOWN:\n",
      "================================================================================\n",
      "\n",
      "Hall 1 (8 labels):\n",
      "  Labels: [6341, 6343, 6345, 6347, 6351, 6353, 6355, 6357]\n",
      "\n",
      "Hall 2 (7 labels):\n",
      "  Labels: [6121, 6141, 6161, 6181, 61101, 61121, 61141]\n",
      "\n",
      "Hall 3 (8 labels):\n",
      "  Labels: [6211, 6231, 6251, 6271, 6291, 62111, 62131, 62151]\n",
      "\n",
      "Room 1 (15 labels):\n",
      "  Labels: [1611, 1613, 1615, 1631, 1633, 1635, 1651, 1653, 1655, 1671, 1673, 1675, 1691, 1693, 1695]\n",
      "\n",
      "Room 10 (12 labels):\n",
      "  Labels: [4311, 4313, 4315, 4331, 4333, 4335, 4351, 4353, 4355, 4371, 4373, 4375]\n",
      "\n",
      "Room 11 (12 labels):\n",
      "  Labels: [4611, 4613, 4615, 4631, 4633, 4635, 4651, 4653, 4655, 4671, 4673, 4675]\n",
      "\n",
      "Room 2 (12 labels):\n",
      "  Labels: [4111, 4113, 4115, 4117, 4131, 4133, 4135, 4137, 4151, 4153, 4155, 4157]\n",
      "\n",
      "Room 3 (8 labels):\n",
      "  Labels: [5711, 5712, 5714, 5716, 5721, 5722, 5724, 5726]\n",
      "\n",
      "Room 4 (9 labels):\n",
      "  Labels: [4011, 4013, 4015, 4031, 4033, 4035, 4051, 4053, 4055]\n",
      "\n",
      "Room 5 (12 labels):\n",
      "  Labels: [5311, 5313, 5315, 5331, 5333, 5335, 5351, 5353, 5355, 5371, 5373, 5375]\n",
      "\n",
      "Room 6 (9 labels):\n",
      "  Labels: [3911, 3913, 3915, 3931, 3933, 3935, 3951, 3953, 3955]\n",
      "\n",
      "Room 7 (12 labels):\n",
      "  Labels: [4711, 4713, 4715, 4731, 4733, 4735, 4751, 4753, 4755, 4771, 4773, 4775]\n",
      "\n",
      "Room 8 (12 labels):\n",
      "  Labels: [5111, 5113, 5115, 5117, 5131, 5133, 5135, 5137, 5151, 5153, 5155, 5157]\n",
      "\n",
      "Room 9 (12 labels):\n",
      "  Labels: [4511, 4513, 4515, 4531, 4533, 4535, 4551, 4553, 4555, 4571, 4573, 4575]\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION OF MAPPING RULES:\n",
      "================================================================================\n",
      "Prefix '16' → Room 1:\n",
      "  Found 15 labels\n",
      "  Sample labels: [1611, 1613, 1615]\n",
      "  Mapping correct: ✓\n",
      "Prefix '41' → Room 2:\n",
      "  Found 12 labels\n",
      "  Sample labels: [4111, 4113, 4115]\n",
      "  Mapping correct: ✓\n",
      "Prefix '57' → Room 3:\n",
      "  Found 8 labels\n",
      "  Sample labels: [5711, 5712, 5714]\n",
      "  Mapping correct: ✓\n",
      "Prefix '40' → Room 4:\n",
      "  Found 9 labels\n",
      "  Sample labels: [4011, 4013, 4015]\n",
      "  Mapping correct: ✓\n",
      "Prefix '53' → Room 5:\n",
      "  Found 12 labels\n",
      "  Sample labels: [5311, 5313, 5315]\n",
      "  Mapping correct: ✓\n",
      "Prefix '39' → Room 6:\n",
      "  Found 9 labels\n",
      "  Sample labels: [3911, 3913, 3915]\n",
      "  Mapping correct: ✓\n",
      "Prefix '47' → Room 7:\n",
      "  Found 12 labels\n",
      "  Sample labels: [4711, 4713, 4715]\n",
      "  Mapping correct: ✓\n",
      "Prefix '51' → Room 8:\n",
      "  Found 12 labels\n",
      "  Sample labels: [5111, 5113, 5115]\n",
      "  Mapping correct: ✓\n",
      "Prefix '45' → Room 9:\n",
      "  Found 12 labels\n",
      "  Sample labels: [4511, 4513, 4515]\n",
      "  Mapping correct: ✓\n",
      "Prefix '43' → Room 10:\n",
      "  Found 12 labels\n",
      "  Sample labels: [4311, 4313, 4315]\n",
      "  Mapping correct: ✓\n",
      "Prefix '46' → Room 11:\n",
      "  Found 12 labels\n",
      "  Sample labels: [4611, 4613, 4615]\n",
      "  Mapping correct: ✓\n",
      "Prefix '63' → Hall 1:\n",
      "  Found 8 labels\n",
      "  Sample labels: [6341, 6343, 6345]\n",
      "  Mapping correct: ✓\n",
      "Prefix '61' → Hall 2:\n",
      "  Found 7 labels\n",
      "  Sample labels: [6121, 6141, 6161]\n",
      "  Mapping correct: ✓\n",
      "Prefix '62' → Hall 3:\n",
      "  Found 8 labels\n",
      "  Sample labels: [6211, 6231, 6251]\n",
      "  Mapping correct: ✓\n",
      "\n",
      "================================================================================\n",
      "SUMMARY:\n",
      "================================================================================\n",
      "✓ Total labels processed: 148\n",
      "✓ Total rooms/areas: 14\n",
      "✓ Room types: 11 Rooms, 3 Halls\n",
      "✓ All labels successfully mapped\n",
      "✓ No unknown labels found\n",
      "\n",
      "Dataframe 'label_room_df' created successfully!\n",
      "Columns: ['LABEL', 'ROOM']\n",
      "Data types: {'LABEL': dtype('int64'), 'ROOM': dtype('O')}\n"
     ]
    }
   ],
   "source": [
    "# Detailed verification and examples for each room\n",
    "print(\"=\"*80)\n",
    "print(\"DETAILED ROOM ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show sample labels for each room\n",
    "print(\"\\nSample labels for each room:\")\n",
    "for room in sorted(label_room_df['ROOM'].unique()):\n",
    "    room_labels = label_room_df[label_room_df['ROOM'] == room]['LABEL'].tolist()\n",
    "    count = len(room_labels)\n",
    "    sample = room_labels[:5]  # Show first 5 labels as examples\n",
    "    print(f\"{room:8} ({count:2d} labels): {sample}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE ROOM BREAKDOWN:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group by room and show all labels\n",
    "for room in sorted(label_room_df['ROOM'].unique()):\n",
    "    room_data = label_room_df[label_room_df['ROOM'] == room]\n",
    "    labels = room_data['LABEL'].tolist()\n",
    "    print(f\"\\n{room} ({len(labels)} labels):\")\n",
    "    print(f\"  Labels: {labels}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICATION OF MAPPING RULES:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify each rule is working correctly\n",
    "for prefix, expected_room in label_to_room_rules.items():\n",
    "    matching_labels = label_room_df[\n",
    "        label_room_df['LABEL'].astype(str).str.startswith(prefix)\n",
    "    ]\n",
    "    \n",
    "    if len(matching_labels) > 0:\n",
    "        actual_rooms = matching_labels['ROOM'].unique()\n",
    "        all_correct = all(room == expected_room for room in actual_rooms)\n",
    "        \n",
    "        print(f\"Prefix '{prefix}' → {expected_room}:\")\n",
    "        print(f\"  Found {len(matching_labels)} labels\")\n",
    "        print(f\"  Sample labels: {matching_labels['LABEL'].head(3).tolist()}\")\n",
    "        print(f\"  Mapping correct: {'✓' if all_correct else '✗'}\")\n",
    "    else:\n",
    "        print(f\"Prefix '{prefix}' → {expected_room}: No labels found\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Total labels processed: {len(label_room_df)}\")\n",
    "print(f\"✓ Total rooms/areas: {label_room_df['ROOM'].nunique()}\")\n",
    "print(f\"✓ Room types: {len([r for r in label_room_df['ROOM'].unique() if 'Room' in r])} Rooms, {len([r for r in label_room_df['ROOM'].unique() if 'Hall' in r])} Halls\")\n",
    "print(f\"✓ All labels successfully mapped\")\n",
    "print(f\"✓ No unknown labels found\")\n",
    "\n",
    "# Save for future use\n",
    "print(f\"\\nDataframe 'label_room_df' created successfully!\")\n",
    "print(f\"Columns: {list(label_room_df.columns)}\")\n",
    "print(f\"Data types: {label_room_df.dtypes.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cd4de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Label-room mapping saved to: ../output/label_room_mapping.csv\n",
      "✓ File contains 148 rows and 2 columns\n",
      "✓ Saved dataframe with columns: ['LABEL', 'ROOM']\n",
      "✓ File successfully created with size: 1,817 bytes\n"
     ]
    }
   ],
   "source": [
    "# Save the label-room mapping dataframe to output directory\n",
    "output_file = '../output/label_room_mapping.csv'\n",
    "label_room_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Label-room mapping saved to: {output_file}\")\n",
    "print(f\"✓ File contains {len(label_room_df)} rows and {len(label_room_df.columns)} columns\")\n",
    "print(f\"✓ Saved dataframe with columns: {list(label_room_df.columns)}\")\n",
    "\n",
    "# Quick verification of saved file\n",
    "import os\n",
    "if os.path.exists(output_file):\n",
    "    file_size = os.path.getsize(output_file)\n",
    "    print(f\"✓ File successfully created with size: {file_size:,} bytes\")\n",
    "else:\n",
    "    print(\"✗ Error: File was not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b15638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "FINAL SUMMARY: ADDITIONAL ANALYSIS DATAFRAMES\n",
      "====================================================================================================\n",
      "\n",
      "1. label_vector_df:\n",
      "   Columns: DEVICE, LABEL_VECTOR\n",
      "   Rows: 10\n",
      "   Description: Device and label vector mapping from test data\n",
      "   File: No (in memory only)\n",
      "\n",
      "2. label_mean_error_df:\n",
      "   Columns: LABEL, MEAN_ERROR\n",
      "   Rows: 148\n",
      "   Description: NN algorithm mean error by label (rho_0=55.0, alpha=4.25)\n",
      "   File: nn_error_by_label.csv\n",
      "\n",
      "3. label_mean_error_slsqp_df:\n",
      "   Columns: LABEL, MEAN_ERROR\n",
      "   Rows: 148\n",
      "   Description: SLSQP+ algorithm mean error by label\n",
      "   File: slsqp_error_by_label.csv\n",
      "\n",
      "4. label_room_df:\n",
      "   Columns: LABEL, ROOM\n",
      "   Rows: 148\n",
      "   Description: Label to room/hall mapping based on prefix rules\n",
      "   File: label_room_mapping.csv\n",
      "\n",
      "====================================================================================================\n",
      "FILES CREATED IN OUTPUT DIRECTORY:\n",
      "====================================================================================================\n",
      "✓ nn_error_by_label.csv (2,440 bytes)\n",
      "✓ slsqp_error_by_label.csv (2,547 bytes)\n",
      "✓ label_room_mapping.csv (1,817 bytes)\n",
      "\n",
      "====================================================================================================\n",
      "KEY INSIGHTS:\n",
      "====================================================================================================\n",
      "• Total unique labels analyzed: 148\n",
      "• Total devices: 10\n",
      "• Total rooms/areas: 14\n",
      "• NN mean error range: 0.000 - 6.575\n",
      "• SLSQP+ mean error range: 0.689 - 6.119\n",
      "• Average NN error: 2.899\n",
      "• Average SLSQP+ error: 2.646\n",
      "• SLSQP+ improvement: 8.7% better than NN\n",
      "\n",
      "====================================================================================================\n",
      "✓ ALL ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "✓ All requested dataframes created and saved\n",
      "✓ Ready for examination board analysis\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# FINAL SUMMARY - ALL DATAFRAMES AND FILES CREATED\n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"FINAL SUMMARY: ADDITIONAL ANALYSIS DATAFRAMES\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "summary_data = [\n",
    "    {\n",
    "        \"DataFrame\": \"label_vector_df\",\n",
    "        \"Columns\": \"DEVICE, LABEL_VECTOR\",\n",
    "        \"Rows\": len(label_vector_df),\n",
    "        \"Description\": \"Device and label vector mapping from test data\",\n",
    "        \"File Saved\": \"No (in memory only)\"\n",
    "    },\n",
    "    {\n",
    "        \"DataFrame\": \"label_mean_error_df\",\n",
    "        \"Columns\": \"LABEL, MEAN_ERROR\",\n",
    "        \"Rows\": len(label_mean_error_df),\n",
    "        \"Description\": \"NN algorithm mean error by label (rho_0=55.0, alpha=4.25)\",\n",
    "        \"File Saved\": \"nn_error_by_label.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"DataFrame\": \"label_mean_error_slsqp_df\", \n",
    "        \"Columns\": \"LABEL, MEAN_ERROR\",\n",
    "        \"Rows\": len(label_mean_error_slsqp_df),\n",
    "        \"Description\": \"SLSQP+ algorithm mean error by label\",\n",
    "        \"File Saved\": \"slsqp_error_by_label.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"DataFrame\": \"label_room_df\",\n",
    "        \"Columns\": \"LABEL, ROOM\", \n",
    "        \"Rows\": len(label_room_df),\n",
    "        \"Description\": \"Label to room/hall mapping based on prefix rules\",\n",
    "        \"File Saved\": \"label_room_mapping.csv\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, item in enumerate(summary_data, 1):\n",
    "    print(f\"\\n{i}. {item['DataFrame']}:\")\n",
    "    print(f\"   Columns: {item['Columns']}\")\n",
    "    print(f\"   Rows: {item['Rows']}\")\n",
    "    print(f\"   Description: {item['Description']}\")\n",
    "    print(f\"   File: {item['File Saved']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FILES CREATED IN OUTPUT DIRECTORY:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "output_files = [\n",
    "    \"nn_error_by_label.csv\",\n",
    "    \"slsqp_error_by_label.csv\", \n",
    "    \"label_room_mapping.csv\"\n",
    "]\n",
    "\n",
    "for file in output_files:\n",
    "    file_path = f\"../output/{file}\"\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path)\n",
    "        print(f\"✓ {file} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"✗ {file} (not found)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(f\"• Total unique labels analyzed: {len(label_room_df)}\")\n",
    "print(f\"• Total devices: {label_vector_df['DEVICE'].nunique()}\")\n",
    "print(f\"• Total rooms/areas: {label_room_df['ROOM'].nunique()}\")\n",
    "print(f\"• NN mean error range: {label_mean_error_df['MEAN_ERROR'].min():.3f} - {label_mean_error_df['MEAN_ERROR'].max():.3f}\")\n",
    "print(f\"• SLSQP+ mean error range: {label_mean_error_slsqp_df['MEAN_ERROR'].min():.3f} - {label_mean_error_slsqp_df['MEAN_ERROR'].max():.3f}\")\n",
    "\n",
    "# Compare algorithms\n",
    "nn_avg = label_mean_error_df['MEAN_ERROR'].mean()\n",
    "slsqp_avg = label_mean_error_slsqp_df['MEAN_ERROR'].mean()\n",
    "improvement = ((nn_avg - slsqp_avg) / nn_avg) * 100\n",
    "\n",
    "print(f\"• Average NN error: {nn_avg:.3f}\")\n",
    "print(f\"• Average SLSQP+ error: {slsqp_avg:.3f}\")\n",
    "print(f\"• SLSQP+ improvement: {improvement:.1f}% better than NN\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"✓ ALL ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"✓ All requested dataframes created and saved\")\n",
    "print(\"✓ Ready for examination board analysis\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c9396",
   "metadata": {},
   "source": [
    "- Error by room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a108957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING AVERAGE ERROR BY ROOM DATAFRAME\n",
      "================================================================================\n",
      "✓ Merged room mapping with NN errors: 148 records\n",
      "✓ Merged room mapping with SLSQP errors: 148 records\n",
      "✓ Created error_by_room_df with 14 rooms\n",
      "✓ Columns: ['ROOM', 'ROOM_TYPE', 'LABEL_COUNT', 'NN_AVG_ERROR', 'SLSQP_AVG_ERROR', 'ERROR_DIFFERENCE', 'IMPROVEMENT_PCT']\n",
      "\n",
      "================================================================================\n",
      "AVERAGE ERROR BY ROOM - COMPLETE RESULTS\n",
      "================================================================================\n",
      "   ROOM ROOM_TYPE  LABEL_COUNT  NN_AVG_ERROR  SLSQP_AVG_ERROR  ERROR_DIFFERENCE  IMPROVEMENT_PCT\n",
      " Hall 1      Hall            8         1.535            1.753            -0.218          -14.194\n",
      " Hall 2      Hall            7         2.033            1.966             0.068            3.330\n",
      " Hall 3      Hall            8         1.630            1.941            -0.311          -19.045\n",
      " Room 1      Room           15         2.934            2.826             0.108            3.694\n",
      "Room 10      Room           12         3.440            2.097             1.343           39.048\n",
      "Room 11      Room           12         3.617            2.805             0.812           22.458\n",
      " Room 2      Room           12         3.054            3.081            -0.027           -0.887\n",
      " Room 3      Room            8         3.460            3.016             0.444           12.828\n",
      " Room 4      Room            9         2.382            2.450            -0.068           -2.845\n",
      " Room 5      Room           12         2.222            2.680            -0.458          -20.592\n",
      " Room 6      Room            9         2.677            2.778            -0.101           -3.785\n",
      " Room 7      Room           12         3.110            3.280            -0.170           -5.464\n",
      " Room 8      Room           12         4.051            3.390             0.662           16.335\n",
      " Room 9      Room           12         3.196            2.226             0.970           30.358\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# AVERAGE ERROR BY ROOM ANALYSIS\n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING AVERAGE ERROR BY ROOM DATAFRAME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Merge room mapping with NN error data\n",
    "nn_room_errors = pd.merge(label_room_df, label_mean_error_df, on='LABEL', how='inner')\n",
    "print(f\"✓ Merged room mapping with NN errors: {len(nn_room_errors)} records\")\n",
    "\n",
    "# Merge room mapping with SLSQP error data  \n",
    "slsqp_room_errors = pd.merge(label_room_df, label_mean_error_slsqp_df, on='LABEL', how='inner')\n",
    "print(f\"✓ Merged room mapping with SLSQP errors: {len(slsqp_room_errors)} records\")\n",
    "\n",
    "# Calculate average errors by room for each algorithm\n",
    "nn_avg_by_room = nn_room_errors.groupby('ROOM')['MEAN_ERROR'].agg(['mean', 'count']).reset_index()\n",
    "nn_avg_by_room.columns = ['ROOM', 'NN_AVG_ERROR', 'NN_LABEL_COUNT']\n",
    "\n",
    "slsqp_avg_by_room = slsqp_room_errors.groupby('ROOM')['MEAN_ERROR'].agg(['mean', 'count']).reset_index()\n",
    "slsqp_avg_by_room.columns = ['ROOM', 'SLSQP_AVG_ERROR', 'SLSQP_LABEL_COUNT']\n",
    "\n",
    "# Merge both algorithm results\n",
    "room_error_comparison = pd.merge(nn_avg_by_room, slsqp_avg_by_room, on='ROOM', how='outer')\n",
    "\n",
    "# Verify label counts match (they should be the same)\n",
    "room_error_comparison['LABEL_COUNT'] = room_error_comparison['NN_LABEL_COUNT']\n",
    "assert all(room_error_comparison['NN_LABEL_COUNT'] == room_error_comparison['SLSQP_LABEL_COUNT']), \"Label counts don't match between algorithms\"\n",
    "\n",
    "# Calculate improvement and add metadata\n",
    "room_error_comparison['ERROR_DIFFERENCE'] = room_error_comparison['NN_AVG_ERROR'] - room_error_comparison['SLSQP_AVG_ERROR']\n",
    "room_error_comparison['IMPROVEMENT_PCT'] = (room_error_comparison['ERROR_DIFFERENCE'] / room_error_comparison['NN_AVG_ERROR']) * 100\n",
    "\n",
    "# Add room type classification\n",
    "room_error_comparison['ROOM_TYPE'] = room_error_comparison['ROOM'].apply(\n",
    "    lambda x: 'Room' if 'Room' in x else 'Hall'\n",
    ")\n",
    "\n",
    "# Select final columns for the main dataframe\n",
    "error_by_room_df = room_error_comparison[['ROOM', 'ROOM_TYPE', 'LABEL_COUNT', \n",
    "                                         'NN_AVG_ERROR', 'SLSQP_AVG_ERROR', \n",
    "                                         'ERROR_DIFFERENCE', 'IMPROVEMENT_PCT']].copy()\n",
    "\n",
    "# Sort by room type and then by room name\n",
    "error_by_room_df = error_by_room_df.sort_values(['ROOM_TYPE', 'ROOM']).reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Created error_by_room_df with {len(error_by_room_df)} rooms\")\n",
    "print(f\"✓ Columns: {list(error_by_room_df.columns)}\")\n",
    "\n",
    "# Display the results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE ERROR BY ROOM - COMPLETE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(error_by_room_df.to_string(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01fa5dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DETAILED ANALYSIS AND INSIGHTS\n",
      "================================================================================\n",
      "Dataset Overview:\n",
      "• Total labels: 148\n",
      "• Total rooms: 11\n",
      "• Total halls: 3\n",
      "\n",
      "Algorithm Performance by Area Type:\n",
      "ROOMS (n=11):\n",
      "  NN average error:    3.104 ± 0.540\n",
      "  SLSQP average error: 2.784 ± 0.408\n",
      "  Average improvement: 8.3%\n",
      "\n",
      "HALLS (n=3):\n",
      "  NN average error:    1.733 ± 0.265\n",
      "  SLSQP average error: 1.887 ± 0.116\n",
      "  Average improvement: -10.0%\n",
      "\n",
      "Best Performing Areas (Lowest SLSQP Error):\n",
      "  Hall 1: 1.753 error (8 labels)\n",
      "  Hall 3: 1.941 error (8 labels)\n",
      "  Hall 2: 1.966 error (7 labels)\n",
      "\n",
      "Worst Performing Areas (Highest SLSQP Error):\n",
      "  Room 8: 3.390 error (12 labels)\n",
      "  Room 7: 3.280 error (12 labels)\n",
      "  Room 2: 3.081 error (12 labels)\n",
      "\n",
      "Greatest Improvements (SLSQP vs NN):\n",
      "  Room 10: 39.0% improvement (1.343 reduction)\n",
      "  Room 9: 30.4% improvement (0.970 reduction)\n",
      "  Room 11: 22.5% improvement (0.812 reduction)\n",
      "\n",
      "Areas where NN performed better:\n",
      "  Hall 1: NN better by 14.2% (0.218 lower error)\n",
      "  Hall 3: NN better by 19.0% (0.311 lower error)\n",
      "  Room 2: NN better by 0.9% (0.027 lower error)\n",
      "  Room 4: NN better by 2.8% (0.068 lower error)\n",
      "  Room 5: NN better by 20.6% (0.458 lower error)\n",
      "  Room 6: NN better by 3.8% (0.101 lower error)\n",
      "  Room 7: NN better by 5.5% (0.170 lower error)\n",
      "\n",
      "================================================================================\n",
      "STATISTICAL SUMMARY:\n",
      "================================================================================\n",
      "Overall Algorithm Comparison:\n",
      "• Weighted average NN error: 2.899\n",
      "• Weighted average SLSQP error: 2.646\n",
      "• Overall improvement: 8.7%\n",
      "• Areas with SLSQP improvement: 7/14 (50.0%)\n",
      "\n",
      "Error Range Analysis:\n",
      "• NN error range: 1.535 - 4.051\n",
      "• SLSQP error range: 1.753 - 3.390\n",
      "• Improvement range: -20.6% - 39.0%\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# DETAILED ANALYSIS OF ROOM-BASED ERROR COMPARISON\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED ANALYSIS AND INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall statistics\n",
    "total_labels = error_by_room_df['LABEL_COUNT'].sum()\n",
    "total_rooms = len(error_by_room_df[error_by_room_df['ROOM_TYPE'] == 'Room'])\n",
    "total_halls = len(error_by_room_df[error_by_room_df['ROOM_TYPE'] == 'Hall'])\n",
    "\n",
    "print(f\"Dataset Overview:\")\n",
    "print(f\"• Total labels: {total_labels}\")\n",
    "print(f\"• Total rooms: {total_rooms}\")\n",
    "print(f\"• Total halls: {total_halls}\")\n",
    "\n",
    "# Algorithm performance by room type\n",
    "rooms_data = error_by_room_df[error_by_room_df['ROOM_TYPE'] == 'Room']\n",
    "halls_data = error_by_room_df[error_by_room_df['ROOM_TYPE'] == 'Hall']\n",
    "\n",
    "print(f\"\\nAlgorithm Performance by Area Type:\")\n",
    "print(f\"ROOMS (n={total_rooms}):\")\n",
    "print(f\"  NN average error:    {rooms_data['NN_AVG_ERROR'].mean():.3f} ± {rooms_data['NN_AVG_ERROR'].std():.3f}\")\n",
    "print(f\"  SLSQP average error: {rooms_data['SLSQP_AVG_ERROR'].mean():.3f} ± {rooms_data['SLSQP_AVG_ERROR'].std():.3f}\")\n",
    "print(f\"  Average improvement: {rooms_data['IMPROVEMENT_PCT'].mean():.1f}%\")\n",
    "\n",
    "print(f\"\\nHALLS (n={total_halls}):\")\n",
    "print(f\"  NN average error:    {halls_data['NN_AVG_ERROR'].mean():.3f} ± {halls_data['NN_AVG_ERROR'].std():.3f}\")\n",
    "print(f\"  SLSQP average error: {halls_data['SLSQP_AVG_ERROR'].mean():.3f} ± {halls_data['SLSQP_AVG_ERROR'].std():.3f}\")\n",
    "print(f\"  Average improvement: {halls_data['IMPROVEMENT_PCT'].mean():.1f}%\")\n",
    "\n",
    "# Best and worst performing areas\n",
    "print(f\"\\nBest Performing Areas (Lowest SLSQP Error):\")\n",
    "best_areas = error_by_room_df.nsmallest(3, 'SLSQP_AVG_ERROR')\n",
    "for _, row in best_areas.iterrows():\n",
    "    print(f\"  {row['ROOM']}: {row['SLSQP_AVG_ERROR']:.3f} error ({row['LABEL_COUNT']} labels)\")\n",
    "\n",
    "print(f\"\\nWorst Performing Areas (Highest SLSQP Error):\")\n",
    "worst_areas = error_by_room_df.nlargest(3, 'SLSQP_AVG_ERROR')\n",
    "for _, row in worst_areas.iterrows():\n",
    "    print(f\"  {row['ROOM']}: {row['SLSQP_AVG_ERROR']:.3f} error ({row['LABEL_COUNT']} labels)\")\n",
    "\n",
    "# Greatest improvements\n",
    "print(f\"\\nGreatest Improvements (SLSQP vs NN):\")\n",
    "best_improvements = error_by_room_df.nlargest(3, 'IMPROVEMENT_PCT')\n",
    "for _, row in best_improvements.iterrows():\n",
    "    print(f\"  {row['ROOM']}: {row['IMPROVEMENT_PCT']:.1f}% improvement ({row['ERROR_DIFFERENCE']:.3f} reduction)\")\n",
    "\n",
    "# Areas where NN performed better\n",
    "nn_better = error_by_room_df[error_by_room_df['IMPROVEMENT_PCT'] < 0]\n",
    "if len(nn_better) > 0:\n",
    "    print(f\"\\nAreas where NN performed better:\")\n",
    "    for _, row in nn_better.iterrows():\n",
    "        print(f\"  {row['ROOM']}: NN better by {abs(row['IMPROVEMENT_PCT']):.1f}% ({abs(row['ERROR_DIFFERENCE']):.3f} lower error)\")\n",
    "else:\n",
    "    print(f\"\\nSLSQP+ performed better or equal in ALL areas!\")\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Overall Algorithm Comparison:\")\n",
    "overall_nn_avg = (error_by_room_df['NN_AVG_ERROR'] * error_by_room_df['LABEL_COUNT']).sum() / total_labels\n",
    "overall_slsqp_avg = (error_by_room_df['SLSQP_AVG_ERROR'] * error_by_room_df['LABEL_COUNT']).sum() / total_labels\n",
    "overall_improvement = ((overall_nn_avg - overall_slsqp_avg) / overall_nn_avg) * 100\n",
    "\n",
    "print(f\"• Weighted average NN error: {overall_nn_avg:.3f}\")\n",
    "print(f\"• Weighted average SLSQP error: {overall_slsqp_avg:.3f}\")\n",
    "print(f\"• Overall improvement: {overall_improvement:.1f}%\")\n",
    "\n",
    "positive_improvements = len(error_by_room_df[error_by_room_df['IMPROVEMENT_PCT'] > 0])\n",
    "print(f\"• Areas with SLSQP improvement: {positive_improvements}/{len(error_by_room_df)} ({positive_improvements/len(error_by_room_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nError Range Analysis:\")\n",
    "print(f\"• NN error range: {error_by_room_df['NN_AVG_ERROR'].min():.3f} - {error_by_room_df['NN_AVG_ERROR'].max():.3f}\")\n",
    "print(f\"• SLSQP error range: {error_by_room_df['SLSQP_AVG_ERROR'].min():.3f} - {error_by_room_df['SLSQP_AVG_ERROR'].max():.3f}\")\n",
    "print(f\"• Improvement range: {error_by_room_df['IMPROVEMENT_PCT'].min():.1f}% - {error_by_room_df['IMPROVEMENT_PCT'].max():.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac83eff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Room error comparison saved to: ../output/average_error_by_room.csv\n",
      "✓ File contains 14 rows and 7 columns\n",
      "✓ File successfully created with size: 1,321 bytes\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY: ROOM-BASED ERROR ANALYSIS\n",
      "================================================================================\n",
      "📊 DATAFRAME CREATED: 'error_by_room_df'\n",
      "   • Dimensions: 14 rooms × 7 columns\n",
      "   • Columns: ['ROOM', 'ROOM_TYPE', 'LABEL_COUNT', 'NN_AVG_ERROR', 'SLSQP_AVG_ERROR', 'ERROR_DIFFERENCE', 'IMPROVEMENT_PCT']\n",
      "   • File saved: average_error_by_room.csv\n",
      "\n",
      "🔍 KEY FINDINGS:\n",
      "   • SLSQP+ shows better performance in ROOMS (8.3% average improvement)\n",
      "   • NN shows better performance in HALLS (-10.0% average improvement)\n",
      "   • Biggest improvement: Room 10 (39.0% better with SLSQP+)\n",
      "   • Biggest regression: Room 5 (20.6% worse with SLSQP+)\n",
      "   • Overall: SLSQP+ is 8.7% better on average across all areas\n",
      "\n",
      "🎯 SPATIAL INSIGHTS:\n",
      "   • Halls generally have lower positioning errors than rooms\n",
      "   • Error variability is higher in rooms than in halls\n",
      "   • Algorithm performance varies significantly by location\n",
      "   • Some areas are more challenging for positioning regardless of algorithm\n",
      "\n",
      "📁 OUTPUT FILES SUMMARY:\n",
      "   ✓ nn_error_by_label.csv (2,440 bytes)\n",
      "   ✓ slsqp_error_by_label.csv (2,547 bytes)\n",
      "   ✓ label_room_mapping.csv (1,817 bytes)\n",
      "   ✓ average_error_by_room.csv (1,321 bytes)\n",
      "\n",
      "================================================================================\n",
      "✅ ROOM-BASED ERROR ANALYSIS COMPLETED!\n",
      "✅ All dataframes created and ready for examination board\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save the room error comparison dataframe\n",
    "output_file_room = '../output/average_error_by_room.csv'\n",
    "error_by_room_df.to_csv(output_file_room, index=False)\n",
    "\n",
    "print(f\"\\n✓ Room error comparison saved to: {output_file_room}\")\n",
    "print(f\"✓ File contains {len(error_by_room_df)} rows and {len(error_by_room_df.columns)} columns\")\n",
    "\n",
    "# Verify file creation\n",
    "import os\n",
    "if os.path.exists(output_file_room):\n",
    "    file_size = os.path.getsize(output_file_room)\n",
    "    print(f\"✓ File successfully created with size: {file_size:,} bytes\")\n",
    "\n",
    "# ================================================================================\n",
    "# FINAL SUMMARY OF ROOM-BASED ANALYSIS\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY: ROOM-BASED ERROR ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"📊 DATAFRAME CREATED: 'error_by_room_df'\")\n",
    "print(f\"   • Dimensions: {len(error_by_room_df)} rooms × {len(error_by_room_df.columns)} columns\")\n",
    "print(f\"   • Columns: {list(error_by_room_df.columns)}\")\n",
    "print(f\"   • File saved: average_error_by_room.csv\")\n",
    "\n",
    "print(f\"\\n🔍 KEY FINDINGS:\")\n",
    "print(f\"   • SLSQP+ shows better performance in ROOMS (8.3% average improvement)\")\n",
    "print(f\"   • NN shows better performance in HALLS (-10.0% average improvement)\")\n",
    "print(f\"   • Biggest improvement: Room 10 (39.0% better with SLSQP+)\")\n",
    "print(f\"   • Biggest regression: Room 5 (20.6% worse with SLSQP+)\")\n",
    "print(f\"   • Overall: SLSQP+ is 8.7% better on average across all areas\")\n",
    "\n",
    "print(f\"\\n🎯 SPATIAL INSIGHTS:\")\n",
    "print(f\"   • Halls generally have lower positioning errors than rooms\")\n",
    "print(f\"   • Error variability is higher in rooms than in halls\")\n",
    "print(f\"   • Algorithm performance varies significantly by location\")\n",
    "print(f\"   • Some areas are more challenging for positioning regardless of algorithm\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT FILES SUMMARY:\")\n",
    "output_files_summary = [\n",
    "    \"nn_error_by_label.csv\",\n",
    "    \"slsqp_error_by_label.csv\", \n",
    "    \"label_room_mapping.csv\",\n",
    "    \"average_error_by_room.csv\"\n",
    "]\n",
    "\n",
    "for file in output_files_summary:\n",
    "    file_path = f\"../output/{file}\"\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path)\n",
    "        print(f\"   ✓ {file} ({size:,} bytes)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"✅ ROOM-BASED ERROR ANALYSIS COMPLETED!\")\n",
    "print(\"✅ All dataframes created and ready for examination board\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d196745f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CORRELATION ANALYSIS: NN ERROR vs SLSQP IMPROVEMENT\n",
      "================================================================================\n",
      "DATAFRAME ORDERED BY NN_AVG_ERROR (Best NN performance → Worst NN performance):\n",
      "================================================================================\n",
      "   ROOM ROOM_TYPE  NN_AVG_ERROR  SLSQP_AVG_ERROR  IMPROVEMENT_PCT\n",
      " Hall 1      Hall         1.535            1.753          -14.194\n",
      " Hall 3      Hall         1.630            1.941          -19.045\n",
      " Hall 2      Hall         2.033            1.966            3.330\n",
      " Room 5      Room         2.222            2.680          -20.592\n",
      " Room 4      Room         2.382            2.450           -2.845\n",
      " Room 6      Room         2.677            2.778           -3.785\n",
      " Room 1      Room         2.934            2.826            3.694\n",
      " Room 2      Room         3.054            3.081           -0.887\n",
      " Room 7      Room         3.110            3.280           -5.464\n",
      " Room 9      Room         3.196            2.226           30.358\n",
      "Room 10      Room         3.440            2.097           39.048\n",
      " Room 3      Room         3.460            3.016           12.828\n",
      "Room 11      Room         3.617            2.805           22.458\n",
      " Room 8      Room         4.051            3.390           16.335\n",
      "\n",
      "================================================================================\n",
      "CORRELATION ANALYSIS RESULTS:\n",
      "================================================================================\n",
      "Pearson Correlation Coefficient: 0.7541\n",
      "P-value: 0.001834\n",
      "Statistical significance: Yes (α = 0.05)\n",
      "Correlation strength: Strong positive correlation\n",
      "\n",
      "📊 INTERPRETATION:\n",
      "• As NN error increases, SLSQP improvement tends to INCREASE\n",
      "• Areas where NN performs poorly benefit MORE from SLSQP optimization\n",
      "\n",
      "================================================================================\n",
      "GROUPED ANALYSIS: BEST vs WORST NN PERFORMING AREAS\n",
      "================================================================================\n",
      "BEST NN PERFORMING AREAS (lowest 4 NN errors):\n",
      "  Average NN error: 1.855\n",
      "  Average SLSQP improvement: -12.6%\n",
      "  Areas: Hall 1, Hall 3, Hall 2, Room 5\n",
      "\n",
      "WORST NN PERFORMING AREAS (highest 4 NN errors):\n",
      "  Average NN error: 3.642\n",
      "  Average SLSQP improvement: 22.7%\n",
      "  Areas: Room 10, Room 3, Room 11, Room 8\n",
      "\n",
      "MIDDLE NN PERFORMING AREAS:\n",
      "  Average NN error: 2.892\n",
      "  Average SLSQP improvement: 3.5%\n",
      "  Areas: Room 4, Room 6, Room 1, Room 2, Room 7, Room 9\n",
      "\n",
      "📈 STATISTICAL COMPARISON (Best vs Worst NN areas):\n",
      "Mann-Whitney U test p-value: 0.028571\n",
      "Significant difference in SLSQP improvement: Yes\n",
      "Difference in average improvement: 35.3 percentage points\n",
      "  (22.7% vs -12.6%)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# CORRELATION ANALYSIS: NN PERFORMANCE vs SLSQP IMPROVEMENT\n",
    "# ================================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS: NN ERROR vs SLSQP IMPROVEMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Order the dataframe by NN_AVG_ERROR (ascending order)\n",
    "error_by_room_ordered = error_by_room_df.sort_values('NN_AVG_ERROR').reset_index(drop=True)\n",
    "\n",
    "print(\"DATAFRAME ORDERED BY NN_AVG_ERROR (Best NN performance → Worst NN performance):\")\n",
    "print(\"=\"*80)\n",
    "print(error_by_room_ordered[['ROOM', 'ROOM_TYPE', 'NN_AVG_ERROR', 'SLSQP_AVG_ERROR', 'IMPROVEMENT_PCT']].to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "import scipy.stats as stats\n",
    "\n",
    "correlation_coef, p_value = stats.pearsonr(error_by_room_ordered['NN_AVG_ERROR'], \n",
    "                                          error_by_room_ordered['IMPROVEMENT_PCT'])\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Pearson Correlation Coefficient: {correlation_coef:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "print(f\"Statistical significance: {'Yes' if p_value < 0.05 else 'No'} (α = 0.05)\")\n",
    "\n",
    "# Interpret correlation strength\n",
    "if abs(correlation_coef) >= 0.7:\n",
    "    strength = \"Strong\"\n",
    "elif abs(correlation_coef) >= 0.5:\n",
    "    strength = \"Moderate\"\n",
    "elif abs(correlation_coef) >= 0.3:\n",
    "    strength = \"Weak\"\n",
    "else:\n",
    "    strength = \"Very weak/No\"\n",
    "\n",
    "direction = \"positive\" if correlation_coef > 0 else \"negative\"\n",
    "print(f\"Correlation strength: {strength} {direction} correlation\")\n",
    "\n",
    "print(f\"\\n📊 INTERPRETATION:\")\n",
    "if correlation_coef > 0:\n",
    "    print(f\"• As NN error increases, SLSQP improvement tends to INCREASE\")\n",
    "    print(f\"• Areas where NN performs poorly benefit MORE from SLSQP optimization\")\n",
    "else:\n",
    "    print(f\"• As NN error increases, SLSQP improvement tends to DECREASE\")\n",
    "    print(f\"• Areas where NN performs poorly benefit LESS from SLSQP optimization\")\n",
    "\n",
    "# Group analysis: Best vs Worst NN performance\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"GROUPED ANALYSIS: BEST vs WORST NN PERFORMING AREAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Split into thirds for analysis\n",
    "n_rooms = len(error_by_room_ordered)\n",
    "third = n_rooms // 3\n",
    "\n",
    "best_nn_areas = error_by_room_ordered.head(third)\n",
    "worst_nn_areas = error_by_room_ordered.tail(third)\n",
    "middle_nn_areas = error_by_room_ordered.iloc[third:-third]\n",
    "\n",
    "print(f\"BEST NN PERFORMING AREAS (lowest {third} NN errors):\")\n",
    "print(f\"  Average NN error: {best_nn_areas['NN_AVG_ERROR'].mean():.3f}\")\n",
    "print(f\"  Average SLSQP improvement: {best_nn_areas['IMPROVEMENT_PCT'].mean():.1f}%\")\n",
    "print(f\"  Areas: {', '.join(best_nn_areas['ROOM'].tolist())}\")\n",
    "\n",
    "print(f\"\\nWORST NN PERFORMING AREAS (highest {third} NN errors):\")\n",
    "print(f\"  Average NN error: {worst_nn_areas['NN_AVG_ERROR'].mean():.3f}\")\n",
    "print(f\"  Average SLSQP improvement: {worst_nn_areas['IMPROVEMENT_PCT'].mean():.1f}%\")\n",
    "print(f\"  Areas: {', '.join(worst_nn_areas['ROOM'].tolist())}\")\n",
    "\n",
    "if len(middle_nn_areas) > 0:\n",
    "    print(f\"\\nMIDDLE NN PERFORMING AREAS:\")\n",
    "    print(f\"  Average NN error: {middle_nn_areas['NN_AVG_ERROR'].mean():.3f}\")\n",
    "    print(f\"  Average SLSQP improvement: {middle_nn_areas['IMPROVEMENT_PCT'].mean():.1f}%\")\n",
    "    print(f\"  Areas: {', '.join(middle_nn_areas['ROOM'].tolist())}\")\n",
    "\n",
    "# Statistical test between groups\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "statistic, p_val_groups = mannwhitneyu(best_nn_areas['IMPROVEMENT_PCT'], \n",
    "                                       worst_nn_areas['IMPROVEMENT_PCT'], \n",
    "                                       alternative='two-sided')\n",
    "\n",
    "print(f\"\\n📈 STATISTICAL COMPARISON (Best vs Worst NN areas):\")\n",
    "print(f\"Mann-Whitney U test p-value: {p_val_groups:.6f}\")\n",
    "print(f\"Significant difference in SLSQP improvement: {'Yes' if p_val_groups < 0.05 else 'No'}\")\n",
    "\n",
    "improvement_diff = worst_nn_areas['IMPROVEMENT_PCT'].mean() - best_nn_areas['IMPROVEMENT_PCT'].mean()\n",
    "print(f\"Difference in average improvement: {improvement_diff:.1f} percentage points\")\n",
    "print(f\"  ({worst_nn_areas['IMPROVEMENT_PCT'].mean():.1f}% vs {best_nn_areas['IMPROVEMENT_PCT'].mean():.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b34dee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VISUAL PATTERN ANALYSIS\n",
      "================================================================================\n",
      "📈 NN ERROR vs SLSQP IMPROVEMENT PATTERN:\n",
      "(Ordered from best NN performance to worst)\n",
      "------------------------------------------------------------\n",
      "🏛️ Hall 1   | NN: 1.535 | SLSQP Imp:  -14.2% ⬇️🟡\n",
      "🏛️ Hall 3   | NN: 1.630 | SLSQP Imp:  -19.0% ⬇️🔴\n",
      "🏛️ Hall 2   | NN: 2.033 | SLSQP Imp:   +3.3% ⬆️🟢\n",
      "🏠 Room 5   | NN: 2.222 | SLSQP Imp:  -20.6% ⬇️🔴\n",
      "🏠 Room 4   | NN: 2.382 | SLSQP Imp:   -2.8% ⬇️🟢\n",
      "🏠 Room 6   | NN: 2.677 | SLSQP Imp:   -3.8% ⬇️🟢\n",
      "🏠 Room 1   | NN: 2.934 | SLSQP Imp:   +3.7% ⬆️🟢\n",
      "🏠 Room 2   | NN: 3.054 | SLSQP Imp:   -0.9% ⬇️🟢\n",
      "🏠 Room 7   | NN: 3.110 | SLSQP Imp:   -5.5% ⬇️🟡\n",
      "🏠 Room 9   | NN: 3.196 | SLSQP Imp:  +30.4% ⬆️🔴\n",
      "🏠 Room 10  | NN: 3.440 | SLSQP Imp:  +39.0% ⬆️🔴\n",
      "🏠 Room 3   | NN: 3.460 | SLSQP Imp:  +12.8% ⬆️🟡\n",
      "🏠 Room 11  | NN: 3.617 | SLSQP Imp:  +22.5% ⬆️🔴\n",
      "🏠 Room 8   | NN: 4.051 | SLSQP Imp:  +16.3% ⬆️🔴\n",
      "\n",
      "================================================================================\n",
      "🔍 KEY INSIGHTS FROM CORRELATION ANALYSIS\n",
      "================================================================================\n",
      "1. 📊 STRONG POSITIVE CORRELATION (r = 0.754, p < 0.01)\n",
      "   • There is a statistically significant strong positive relationship\n",
      "   • Areas with higher NN errors benefit MORE from SLSQP+ optimization\n",
      "   • This suggests SLSQP+ is particularly effective in challenging environments\n",
      "\n",
      "2. 🎯 ALGORITHM COMPLEMENTARITY:\n",
      "   • Best NN areas (Halls): NN performs better, SLSQP+ shows regression (-12.6%)\n",
      "   • Worst NN areas (Complex Rooms): SLSQP+ shows major improvements (+22.7%)\n",
      "   • 35.3 percentage point difference between groups (statistically significant)\n",
      "\n",
      "3. 🏛️ SPATIAL PATTERNS:\n",
      "   • HALLS: NN algorithm works well, SLSQP+ adds complexity without benefit\n",
      "   • SIMPLE ROOMS: Mixed results, moderate improvements\n",
      "   • COMPLEX ROOMS: SLSQP+ optimization provides substantial benefits\n",
      "\n",
      "4. 🔧 PRACTICAL IMPLICATIONS:\n",
      "   • Use NN algorithm for halls and simple environments\n",
      "   • Use SLSQP+ optimization for complex rooms with high positioning challenges\n",
      "   • Hybrid approach could optimize performance based on environment complexity\n",
      "\n",
      "================================================================================\n",
      "📋 RECOMMENDATION SUMMARY\n",
      "================================================================================\n",
      "🎯 ALGORITHM SELECTION STRATEGY:\n",
      "   • NN Error < 2.5:    Use Nearest Neighbor (simpler, faster)\n",
      "   • NN Error 2.5-3.2:  Evaluate case-by-case\n",
      "   • NN Error > 3.2:    Use SLSQP+ (significant improvements expected)\n",
      "\n",
      "🏗️ ENVIRONMENT-BASED APPROACH:\n",
      "   • Halls (open spaces):     Nearest Neighbor recommended\n",
      "   • Simple rooms:            Nearest Neighbor or lightweight optimization\n",
      "   • Complex rooms:           SLSQP+ optimization recommended\n",
      "\n",
      "✅ CORRELATION VALIDATED:\n",
      "   The hypothesis that SLSQP+ helps more in challenging areas is CONFIRMED\n",
      "   with strong statistical evidence (r=0.754, p=0.0018)\n",
      "\n",
      "💾 ORDERED DATAFRAME SAVED: ../output/error_by_room_ordered_by_nn.csv\n",
      "   (Sorted by NN_AVG_ERROR ascending for correlation analysis)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# VISUAL SUMMARY AND KEY INSIGHTS\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUAL PATTERN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"📈 NN ERROR vs SLSQP IMPROVEMENT PATTERN:\")\n",
    "print(\"(Ordered from best NN performance to worst)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for idx, row in error_by_room_ordered.iterrows():\n",
    "    room_type_symbol = \"🏛️\" if row['ROOM_TYPE'] == 'Hall' else \"🏠\"\n",
    "    improvement_symbol = \"⬆️\" if row['IMPROVEMENT_PCT'] > 0 else \"⬇️\"\n",
    "    improvement_magnitude = \"🔴\" if abs(row['IMPROVEMENT_PCT']) > 15 else \"🟡\" if abs(row['IMPROVEMENT_PCT']) > 5 else \"🟢\"\n",
    "    \n",
    "    print(f\"{room_type_symbol} {row['ROOM']:8} | NN: {row['NN_AVG_ERROR']:5.3f} | SLSQP Imp: {row['IMPROVEMENT_PCT']:+6.1f}% {improvement_symbol}{improvement_magnitude}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🔍 KEY INSIGHTS FROM CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"1. 📊 STRONG POSITIVE CORRELATION (r = 0.754, p < 0.01)\")\n",
    "print(\"   • There is a statistically significant strong positive relationship\")\n",
    "print(\"   • Areas with higher NN errors benefit MORE from SLSQP+ optimization\")\n",
    "print(\"   • This suggests SLSQP+ is particularly effective in challenging environments\")\n",
    "\n",
    "print(\"\\n2. 🎯 ALGORITHM COMPLEMENTARITY:\")\n",
    "print(\"   • Best NN areas (Halls): NN performs better, SLSQP+ shows regression (-12.6%)\")\n",
    "print(\"   • Worst NN areas (Complex Rooms): SLSQP+ shows major improvements (+22.7%)\")\n",
    "print(\"   • 35.3 percentage point difference between groups (statistically significant)\")\n",
    "\n",
    "print(\"\\n3. 🏛️ SPATIAL PATTERNS:\")\n",
    "print(\"   • HALLS: NN algorithm works well, SLSQP+ adds complexity without benefit\")\n",
    "print(\"   • SIMPLE ROOMS: Mixed results, moderate improvements\")\n",
    "print(\"   • COMPLEX ROOMS: SLSQP+ optimization provides substantial benefits\")\n",
    "\n",
    "print(\"\\n4. 🔧 PRACTICAL IMPLICATIONS:\")\n",
    "print(\"   • Use NN algorithm for halls and simple environments\")\n",
    "print(\"   • Use SLSQP+ optimization for complex rooms with high positioning challenges\")\n",
    "print(\"   • Hybrid approach could optimize performance based on environment complexity\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 RECOMMENDATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"🎯 ALGORITHM SELECTION STRATEGY:\")\n",
    "print(\"   • NN Error < 2.5:    Use Nearest Neighbor (simpler, faster)\")\n",
    "print(\"   • NN Error 2.5-3.2:  Evaluate case-by-case\")  \n",
    "print(\"   • NN Error > 3.2:    Use SLSQP+ (significant improvements expected)\")\n",
    "\n",
    "print(\"\\n🏗️ ENVIRONMENT-BASED APPROACH:\")\n",
    "print(\"   • Halls (open spaces):     Nearest Neighbor recommended\")\n",
    "print(\"   • Simple rooms:            Nearest Neighbor or lightweight optimization\")\n",
    "print(\"   • Complex rooms:           SLSQP+ optimization recommended\")\n",
    "\n",
    "print(f\"\\n✅ CORRELATION VALIDATED:\")\n",
    "print(f\"   The hypothesis that SLSQP+ helps more in challenging areas is CONFIRMED\")\n",
    "print(f\"   with strong statistical evidence (r={correlation_coef:.3f}, p={p_value:.4f})\")\n",
    "\n",
    "# Save the ordered dataframe\n",
    "ordered_output_file = '../output/error_by_room_ordered_by_nn.csv'\n",
    "error_by_room_ordered.to_csv(ordered_output_file, index=False)\n",
    "print(f\"\\n💾 ORDERED DATAFRAME SAVED: {ordered_output_file}\")\n",
    "print(f\"   (Sorted by NN_AVG_ERROR ascending for correlation analysis)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
